<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Martin Kolnes, Karin Täht" />


<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Kodu</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Praktikumide materjalid
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="praktikum1.html">1. Praktikum - sissejuhatus</a>
    </li>
    <li>
      <a href="praktikum2.html">2. Praktikum - joonised</a>
    </li>
    <li>
      <a href="praktikum3.html">3. Praktikum - ANOVA</a>
    </li>
    <li>
      <a href="praktikum4v2.html">4. Praktikum - regressioon</a>
    </li>
    <li>
      <a href="praktikum5.html">5. Praktikum - logistiline regressioon</a>
    </li>
    <li>
      <a href="praktikum6.html">6. Praktikum - eksploratiivne faktoranaluus</a>
    </li>
    <li>
      <a href="praktikum7.html">7. Praktikum - Struktuurvorrandite mudelid</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lisamaterjalid
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lisa_andmente_importimine.html">Andmete importimine</a>
    </li>
    <li>
      <a href="praktikum1_korrelatsioon.html">Korrelatsioon</a>
    </li>
    <li>
      <a href="praktikum1_subsetting.html">Andmete eraldamine</a>
    </li>
    <li>
      <a href="praktikum2_ttestid.html">Keskmiste vordlemine</a>
    </li>
    <li>
      <a href="lisa_joonis.html">Joonis - keskmised</a>
    </li>
  </ul>
</li>
<li>
  <a href="lugemist.html">Soovitused</a>
</li>
<li>
  <a href="about.html">Kontakt</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore"><ol start="4" style="list-style-type: decimal">
<li>praktikum: Regressioonanalüüs</li>
</ol></h1>
<h4 class="author"><em>Martin Kolnes, Karin Täht</em></h4>

</div>


<p>Laadige alla <a href="https://drive.google.com/open?id=1QJQfP9tCL5nBlSQadJmnznyYuN33_Pmf">praktikumi andmed</a>.</p>
<div id="kordamine" class="section level1">
<h1>Kordamine</h1>
<p>Kasutage andemstikku nimega “pisa”.</p>
<ol style="list-style-type: decimal">
<li>Vaadake kirjeldavaid statistikuid matemaatik (PV1MATH), lugemise (PV1READ) ja loodusteaduste (PV1SCIE) alatestide tulemuste kohta.</li>
</ol>
<pre class="r"><code>summary(pisa)</code></pre>
<pre><code>##        X            PVMATH          PVREAD          PVSCIE     
##  Min.   :   1   Min.   :217.3   Min.   :171.3   Min.   :250.8  
##  1st Qu.:1193   1st Qu.:467.9   1st Qu.:452.9   1st Qu.:480.8  
##  Median :2384   Median :517.8   Median :507.8   Median :535.6  
##  Mean   :2384   Mean   :518.2   Mean   :504.4   Mean   :535.0  
##  3rd Qu.:3576   3rd Qu.:570.7   3rd Qu.:561.4   3rd Qu.:591.1  
##  Max.   :4768   Max.   :747.6   Max.   :721.3   Max.   :778.1  
##     GENSCIE           INSTSCIE          INTSCIE           JOYSCIE        
##  Min.   :-3.6618   Min.   :-2.1025   Min.   :-3.1448   Min.   :-2.15170  
##  1st Qu.:-0.3580   1st Qu.:-0.4167   1st Qu.:-0.2320   1st Qu.:-0.58250  
##  Median : 0.0792   Median : 0.0195   Median : 0.2143   Median :-0.10280  
##  Mean   : 0.1521   Mean   : 0.0609   Mean   : 0.1956   Mean   : 0.01382  
##  3rd Qu.: 0.8962   3rd Qu.: 0.3719   3rd Qu.: 0.6732   3rd Qu.: 0.53910  
##  Max.   : 2.1867   Max.   : 1.8212   Max.   : 3.2888   Max.   : 2.05620  
##     PERSCIE           SCIEEFF            SCIEFUT             SCSCIE       
##  Min.   :-3.0797   Min.   :-3.76820   Min.   :-1.41860   Min.   :-2.3632  
##  1st Qu.:-0.5345   1st Qu.:-0.56540   1st Qu.:-0.69380   1st Qu.:-0.3218  
##  Median : 0.0553   Median :-0.05300   Median :-0.04920   Median : 0.0752  
##  Mean   : 0.1460   Mean   : 0.04218   Mean   :-0.08318   Mean   : 0.1147  
##  3rd Qu.: 0.7259   3rd Qu.: 0.51790   3rd Qu.: 0.58830   3rd Qu.: 0.6520  
##  Max.   : 2.5264   Max.   : 3.22300   Max.   : 2.27140   Max.   : 2.2442  
##        GR         GENDER  
##  Min.   : 7.000   F:2352  
##  1st Qu.: 8.000   M:2416  
##  Median : 9.000           
##  Mean   : 8.725           
##  3rd Qu.: 9.000           
##  Max.   :10.000</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Tehke eraldi histogrammid soo alusel loodusteaduste testi tulemuste kohta.</li>
</ol>
<pre class="r"><code>library(ggplot2)
ggplot(data=pisa, aes(x= PVSCIE))+
        geom_histogram()+
        facet_wrap(~GENDER)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="praktikum4v2_files/figure-html/unnamed-chunk-3-1.png" width="672" /> 3. Missugused on korrelatsioonid nende kolme testi (PV1MATH, PV1READ, PV1SCIE) vahel?</p>
<pre class="r"><code>library(&quot;psych&quot;)
corr.test()#argumendiks saate panna mitu veergu</code></pre>
<pre class="r"><code>library(psych)</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre class="r"><code>corr.test(pisa[,c(&quot;PVMATH&quot;, &quot;PVREAD&quot;, &quot;PVSCIE&quot;)])</code></pre>
<pre><code>## Call:corr.test(x = pisa[, c(&quot;PVMATH&quot;, &quot;PVREAD&quot;, &quot;PVSCIE&quot;)])
## Correlation matrix 
##        PVMATH PVREAD PVSCIE
## PVMATH   1.00   0.84   0.92
## PVREAD   0.84   1.00   0.86
## PVSCIE   0.92   0.86   1.00
## Sample Size 
## [1] 4768
## Probability values (Entries above the diagonal are adjusted for multiple tests.) 
##        PVMATH PVREAD PVSCIE
## PVMATH      0      0      0
## PVREAD      0      0      0
## PVSCIE      0      0      0
## 
##  To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
<p>Regressioonanalüüs on üks kõige sagedamini kasutatavaid statistilisi meetodeid. Selle eesmärgiks on tuletada valem, mis seostab omavahel sõltuva muutuja ja ühe või mitu sõltumatut muutujat ehk prediktorit. Tuletatud valemit võib kasutada sõltuva muutuja väärtuste ennustamiseks prediktorite väärtuste põhjal. Aga enamasti kasutatakse seda määramaks kindlaks, kas ja millised sõltumatud muutujad omavad olulist seost sõltumatu muutujaga. Oletame, et oleme inimeste kohta mõõtnud kahte näitajat, nimetagem neid X ja Y. Me tahame ennustada Y väärtusi (sõltuv muutuja) X-i väärtuste kaudu (sõltumatu muutuja). Sellisel juhul saame nendevahelise regressioonseose valemi kirjutada nii: <span class="math display">\[Y = b_{0} + b_{1}X + e\]</span><br />
Y ja X tähistavad selles vastavalt inimeste sõltuva ja sõltumatu tunnuse väärtusi. <span class="math inline">\(b_0\)</span> on vabaliige, mis ütleb, milline on sõltuva muutuja Y väärtus, kui sõltumatu muutuja X väärtus on 0. <span class="math inline">\(b_1\)</span> on regressioonikordaja, mis ütleb, kui palju muutub sõltuv muutuja Y juhul kui sõltumatu muutuja X väärtus muutub ühe ühiku võrra. <span class="math inline">\(b_0\)</span> ja <span class="math inline">\(b_1\)</span> nimetame mudeli parameetriteks, need on inimeste jaoks ühised. <span class="math inline">\(e\)</span> on mudeli viga (nimetatakse ka jääkideks või hälveteks). Mudel ei suuda reeglina andmeid seletada täielikult ja <span class="math inline">\(e\)</span> ongi mudeli ja tegelike andmete vaheline erinevus mingi konkreetse inimese puhul. Regressioonianalüüsi puhul anname statistikaprogrammile ette inimeste X ja Y väärtuse ning saame tagasi b-de väärtuse ja iga inimese kohta ka <span class="math inline">\(e\)</span> väärtuse. Kui oleme mõõtnud kolme muutujat (nimetagem neid Y , X1 ja X2) ja tahame teada kas X1 ja X2 mõlemad mõjutavad Y -it, omandaks valem sellise kuju: <span class="math display">\[Y = b_{0} + b_{1}X_{1} + b_{2}X_{2} + e\]</span></p>
<p>Ehk siis üks bX korrutis on valemisse juurde tulnud ja sellest tulenevalt on vaja kindlaks määrata väärtus ühe täiendava <span class="math inline">\(b\)</span> jaoks. üldistatult võibki öelda, et iga täiendav sõltumatu muutuja lisab valemisse veel ühe <span class="math inline">\(bX\)</span> korrutise ja kindlaks määramist vajab üks täiendav parameeter.</p>
</div>
<div id="paarisregressioon" class="section level1">
<h1>Paarisregressioon</h1>
<p>Avage andmefail <strong>pisa</strong>.<br />
Teeme alustuseks lihtsa regressioonanalüüsi mudeli, milles on sõltuv tunnus ja ainult üks sõltumatu tunnus ehk prediktor. Võtame sõltuvaks tunnuseks PISA uuringu loodusteaduste alatesti skoori (tunnus nimega PVSCIE) ja ennustame seda matemaatika alatesti skoori kaudu (tunnus nimega PVMATH).</p>
<div id="eeldus---lineaarne-seose-kuju-soltuva-ja-soltumatute-tunnuste-vahel" class="section level3">
<h3>Eeldus - lineaarne seose kuju sõltuva ja sõltumatute tunnuste vahel</h3>
<p>Teeme kõigepealt tavalise hajuvusdiagrammi, et hinnata muutujate vahelise seose olemust. Siin tahame näha lineaarset seost sõltuva ja sõltumatute tunnuste vahel. Antud juhul on meil muutujad tugevalt seotud ja näeme joonise selget lineaarset seost.</p>
<pre class="r"><code>plot(x = pisa$PVMATH, y = pisa$PVSCIE)</code></pre>
<p><img src="praktikum4v2_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="mudeli-koostamine" class="section level3">
<h3>Mudeli koostamine</h3>
<p>Mudeli koostamiseks kasutame R-i funktsiooni <em>lm (linear model)</em>, millele anname mudelisse minevad muutujad valemi kujul ja argumendi <em>data</em> abil andmetabeli nime, millest muutujad võetakse. Funktsiooni lm() kasutamine:<br />
<strong>lm(sõltuv tunnus <span class="math inline">\(\sim\)</span> sõltumatu tunnus, data=andmestiku nimi)</strong></p>
<pre class="r"><code>pisa.mudel1 &lt;- lm(PVSCIE ~ PVMATH, data=pisa)</code></pre>
<p>Salvestasime mudeli nimega <em>pisa.mudel1</em>. Selle nime abil saame hiljem kätte meid huvitavad mudeli parameetrid ja ka mudeli jäägid. Kui mudelisse kaasatud muutujates esineb puuduvaid andmeid, tuleb nende välja jätmiseks lisada funktsioonile lm veel täiendav argument na.action=na.omit. Nüüd kui oleme mudeli defineerinud, vaatame mudeli väljundit, mille saame kätte funktsiooni <em>summary</em> abil:</p>
<pre class="r"><code>summary(pisa.mudel1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = PVSCIE ~ PVMATH, data = pisa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -130.546  -21.008   -0.288   20.401  133.671 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 29.203022   3.194110   9.143   &lt;2e-16 ***
## PVMATH       0.976174   0.006101 160.013   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31.56 on 4766 degrees of freedom
## Multiple R-squared:  0.8431, Adjusted R-squared:  0.843 
## F-statistic: 2.56e+04 on 1 and 4766 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Mida mudeli väljundi osad tähendavad? Kuna seda tüüpi väljund on antud praktikumis üks kõige olulisemaid, siis vaatame selle üksikasjalikumalt läbi. Hakkame väljundi ülaosast pihta ja liigume järjest allapoole. Tuleb rõhutada, et tegemist pole väljundi osade tähtsuse järjekorraga.</p>
<p>Esimene osa <strong>Call</strong> lihtsalt kordab üle, millised muutujad on mudelisse kaasatud.</p>
<p><strong>Residuals</strong> toob ära mõned näitajad mudeli jääkide kohta. Mudeli jäägid kujutavad endast erinevust andmete ja mudeli vahel. Tegemist on selle osaga andmetest, mida mudel ära seletada ei suuda. Teatavasti peaksid regressioonimudeli jäägid olema normaaljaotusega ja mediaan peaks olema 0-i ligiduses. See tähendab, et 1. kvartiil (1Q) ja 3. kvartiil (3Q) peaksid olema vastasmärgilised aga absoluutväärtuselt sarnased. Samamoodi ka Min ja Max, kuigi nende puhul on suuremad erinevused üsna tavalised. Kui erinevused on väga suured, võib tekkida probleeme mudeli üldistamisel teistele valimitele. Jääke vaatame hiljem lähemalt, see rida siin võimaldab ainult kiirpilku.</p>
<p>Tabelis <strong>Coefficients</strong> on kirjas mudeli parameetrid koos nende statistilise usaldusväärsuse näitajatega. Esimesel real (Intercept) tulbas <strong>Estimate</strong> on toodud mudeli vabaliikme väärtus (antud juhul 29.203). Seda võib tõlgendada nii, et kui sõltumatu muutuja väärtuseks on 0, siis mudel ennustab loodusteaduste alatesti skooriks just selle numbri. Teisel real tulbas <strong>Estimate</strong> on toodud sõltumatu tunnuse PVMATH (matemaatika alatesti tulemus) regressioonikordaja, mille väärtuseks on 0.976. See tähendab, et kui sõltumatu tunnus muutub ühe ühiku võrra, muutub sõltuv tunnus 0.976 ühiku võrra. Antud juhul on kordaja positiivne, mis tähendab, et kui sõltumatu muutuja suureneb, kasvab ka sõltuv muutuja. Negatiivne kordaja tähendab, et sõltumatu muutuja suurenedes sõltuv muutuja hoopis väheneb. Kui prediktor omab olulist seost sõltuva muutujaga, peaks kordaja olema nullist erinev. Tulbas <strong>Std. Error</strong> on toodud regressioonikordaja standardviga. Standardviga näitab, kui erinevad oleksid antud regressioonikordaja väärtused erinevates valimites. Väike standardviga tähendab, et ka teistes valimites võib oodata antud valimi omale sarnast kordajat. Tulbas <strong>t-value</strong> on toodud t-väärtus mis kujutab, endast regressioonikordaja ja standardvea suhet. Olulist seost omavate prediktorite puhul peaks regressioonikordaja olema standardveaga võrreldes võimalikult suur. Laias laastus võib öelda, et vähemalt 2 korda suurem ehk siis t &gt; 2. (Sellest järeldub ka, et väikese standardvea korral võib ka väike reg.kordaja olla oluline). Tulbas <strong>Pr(&gt;|t|)</strong> on toodud p-väärtus, mis kontrollib hüpoteesi, et t väärtus pole 0-st oluliselt erinev. Antud juhul tähistab *** lõpus, et p &lt; 0.001, mis viitab, et tõenäosus, et t pole 0-st erinev on alla 0.1% ehk väga väike ja sellest tulenevalt võib õelda, et sõltumatu tunnus PVMATH (ehk matemaatika alatesti tulemus) omab statistiliselt usaldusväärset seost loodusteaduste alatesti skooriga.</p>
<p>Tabeli järel on selgitus selle kohta, milline tärnide arv tabeliridade lõpus, tähistab millist statistilise olulisuse nivood. Seejärel on toodud näitaja <strong>Residual standard error</strong>, mis kujutab endast põhimõtteliselt mudeli jääkide standardhälvet, aga üldiselt see meid väga ei huvita.</p>
<p><strong>Multiple R-squared</strong> on mudeli determinatsioonikordaja (<span class="math inline">\(R^2\)</span>), mis näitab, kui suure osa sõltuva tunnuse hajuvusest mudel (mis antud juhul koosneb ainult tunnusest GENSCIE) ära seletab. Praegusel juhul on selle väärtuseks 0.843, korrutades selle 100-ga saame näitaja protsentides ehk siis 84.3% alatesti skooride hajuvusest saab seletada tunnuse PVMATH abil (ja 15.7% hajuvusest tingitud mingitest muudest asjaoludest). <strong>Adjusted R-squared</strong> näitab, kui suurt <span class="math inline">\(R^2\)</span>-e võime oodata kui hinnata seost antud valimi asemel terves populatsioonis. See näitaja on alati väiksem, kui Multiple R-squared, aga praegusel juhul (0.843) on erinevus väga väike, mis on suures osas tingitud ka sellest, et meie valim on väga suur.</p>
<p>Viimasel real on ära toodud <strong>F-suhe</strong> koos oma vabadusastmete ja p-väärtusega. Näitaja kujutab, endast mudeli poolt seletatava hajuvuse ja jääkhajuvuse suhet. Mida suurem on F-suhe seda parem, rea lõpus toodud p-väärtus aitab hinnata F-suhte suurust ja seeläbi mudeli kvaliteeti. Antud juhul on F-suhte p-väärtus &lt; 2.2e-16, see tähendab väiksem kui <span class="math inline">\(2.2 * 10^-16\)</span> ehk siis tõenäosus, et nii suur F-suhe on saadud ainult tänu juhusele on väga väike.</p>
<p><span class="math inline">\(R^2\)</span> ja F-suhe on saadud võrreldes mudelit sellise mudeliga, milles muutujate-vaheline seos puudub (ainult vabaliikmega mudel, vabaliikme väärtuseks võetakse sõltuva muutuja keskmine). Võime järeldada, et meie mudel on parem kui mudel, milles muutujate vaheline seos puudub.</p>
<p>Mudeli väljundist teada saadud parameetrite abil võime loodusteaduste alatesti ja teaduse oluliseks pidamise seost väljendada järgevalt:</p>
<p><span class="math display">\[loodusteaduste alatesti skoor = 29.203 + 0.976 * matemaatika alatesti skoor\]</span></p>
</div>
<div id="eeldus---jaagid-peaksid-jaotuma-normaaljaotuse-kohaselt" class="section level3">
<h3>Eeldus - jäägid peaksid jaotuma normaaljaotuse kohaselt</h3>
<p>Regressioonimudeli jäägid olema normaaljaotusega. Selle testimiseks saame kasutada juba eelmisest praktikumist tuttavaid meetodeid.</p>
<pre class="r"><code># Teeme Shapiro-Wilki testi. Kui p-väärtus on alla 0.05, siis ei ole normaaljaotusel vastav.
shapiro.test(pisa.mudel1$residuals)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  pisa.mudel1$residuals
## W = 0.99858, p-value = 0.0003098</code></pre>
<pre class="r"><code># Illustreerimiseks saame kasutada histogrammi:
hist(pisa.mudel1$residuals)</code></pre>
<p><img src="praktikum4v2_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="ulesanded---paarisregressioon" class="section level3">
<h3>Ülesanded - paarisregressioon</h3>
<ol style="list-style-type: decimal">
<li>Tehke paarisregressiooni mudel, mis ennustab loodusteaduse alatesti skoori (tunnus PVSCIE) teaduse nautimise kaudu (JOYSCIE). Kas seos on oluline? Kui suure osa matemaatika testi skooride hajuvusest mudel ära seletab? Mitme punkti võrra muutub matemaatika skoor kui sõltumatu muutuja muutub ühe punkti võrra?</li>
</ol>
<pre class="r"><code>plot(y = pisa$PVSCIE, x = pisa$JOYSCIE) </code></pre>
<p><img src="praktikum4v2_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>pisa.mudel.yl1 = lm(PVSCIE ~ JOYSCIE, data = pisa)
summary(pisa.mudel.yl1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = PVSCIE ~ JOYSCIE, data = pisa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -287.656  -51.782    1.224   55.309  239.658 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  534.748      1.123  475.99   &lt;2e-16 ***
## JOYSCIE       21.342      1.321   16.16   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 77.56 on 4766 degrees of freedom
## Multiple R-squared:  0.05193,    Adjusted R-squared:  0.05173 
## F-statistic: 261.1 on 1 and 4766 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div id="mitmene-regressioon" class="section level1">
<h1>Mitmene regressioon</h1>
<p>Teeme uue regressioonimudeli, milles jääb sõltuva muutujana alles loodusteaduste alatesti skoor (PVSCIE) ja prediktorina teaduse nautimine (GENSCIE). Lisame veel kaks uut prediktorit: huvi teaduse vastu (INTSCIE) ja motivatsioon loodusteaduste õppimiseks (INSTSCIE).</p>
<div id="eeldus---multikollineaarsus" class="section level3">
<h3>Eeldus - multikollineaarsus</h3>
<p>Lisaks paarisregressiooni eeldustele peame vaatama mitmese regressiooni puhul ka prediktorite vahelisi korrelatsioone. Regressioonanalüüsi puhul tahame, et sõltumatud tunnused oleksid võimalikult tugevalt seotud sõltuva tunnusega, kuid samas võimalikult vähe seotud omavahel. Üheks probleemiks, mis esineda võib, on multikollineaarsus ehk olukord, kui mudeli prediktorid on omavahel liiga tugevalt korreleeritud. Probleemse multikollineaarsuse avastamiseks võime vaadata prediktorite-vahelisi korrelatsioone.</p>
<pre class="r"><code>library(&quot;psych&quot;) #soovitan kasutada funktsiooni corr.test, mis asub antud paketis
corr.test(subset(pisa, select = c(&quot;PVSCIE&quot;, &quot;JOYSCIE&quot;,&quot;INTSCIE&quot;,&quot;INSTSCIE&quot;)))</code></pre>
<pre><code>## Call:corr.test(x = subset(pisa, select = c(&quot;PVSCIE&quot;, &quot;JOYSCIE&quot;, &quot;INTSCIE&quot;, 
##     &quot;INSTSCIE&quot;)))
## Correlation matrix 
##          PVSCIE JOYSCIE INTSCIE INSTSCIE
## PVSCIE     1.00    0.23    0.17     0.03
## JOYSCIE    0.23    1.00    0.55     0.48
## INTSCIE    0.17    0.55    1.00     0.41
## INSTSCIE   0.03    0.48    0.41     1.00
## Sample Size 
## [1] 4768
## Probability values (Entries above the diagonal are adjusted for multiple tests.) 
##          PVSCIE JOYSCIE INTSCIE INSTSCIE
## PVSCIE     0.00       0       0     0.02
## JOYSCIE    0.00       0       0     0.00
## INTSCIE    0.00       0       0     0.00
## INSTSCIE   0.02       0       0     0.00
## 
##  To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
</div>
<div id="mudeli-koostamine-1" class="section level3">
<h3>Mudeli koostamine</h3>
<p>Mudeli koostamiseks kasutama sama funktsiooni:</p>
<pre class="r"><code>pisa.mudel2 &lt;- lm(PVSCIE ~ JOYSCIE + INTSCIE + INSTSCIE, data=pisa)</code></pre>
<p>Nagu näha on mudeli valemi paremal poolel olevad sõltumatud muutujad omavahel eraldatud + märgiga. Vaatame mudeli väljundit, mille saime funktsiooni <em>summary</em> abil.</p>
<pre class="r"><code>summary(pisa.mudel2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = PVSCIE ~ JOYSCIE + INTSCIE + INSTSCIE, data = pisa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -284.848  -51.022    1.409   55.191  234.832 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  533.688      1.167 457.175  &lt; 2e-16 ***
## JOYSCIE       22.028      1.662  13.252  &lt; 2e-16 ***
## INTSCIE        8.895      1.833   4.851 1.26e-06 ***
## INSTSCIE     -11.315      1.657  -6.828 9.70e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 77.1 on 4764 degrees of freedom
## Multiple R-squared:  0.06357,    Adjusted R-squared:  0.06298 
## F-statistic: 107.8 on 3 and 4764 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Vaatame mudeli üldist sobitusastet näitavat determinatsioonikordajat <span class="math inline">\(R^2\)</span> (Multiple R-squared) väljundi alaosas. Selle väärtuseks on 0.06357. Korrutades selle 100-ga saame, et mudel seletab ära umbes 6.4% sõltuva muutuja hajuvusest.</p>
<p>Järgmisena uurime tabelis <strong>Coefficients</strong> tulbas <strong>Estimates</strong> olevaid mudeli parameetrite väärtusi. Vabaliikme väärtus on 533.688. See tähendab, et kui kõigi kolme prediktori väärtus juhtub olema 0, võime oodata sellist loodusteaduste testi skoori. Kõik kolm prediktorit omavad olulist seost sõltuva muutujaga. Tunnuse JOYSCIE (teaduse nautimine) regressioonikordaja on 22.028. Mitmese regressiooni korral näitavad regressioonikordajad, millisel määral iga prediktor mõjutab sõltuvat muutujat eeldusel, et teised prediktorid samal ajal ei muutu. See tähendab, et kui JOYSCIE suureneb ühe ühiku võrra, võime oodata, et testiskoor suureneb 22.028 ühiku võrra. Seda eeldusel, et kahe ülejäänud prediktori väärtused jäävad samaks. Tunnuse INTSCIE (huvi teaduse vastu) regressioonikordaja on 8.895. Kui see muutuja suureneb ühe punkti võrra, võib eeldada testiskoori 8.9-punktist kasvu (jällegi eeldusel, et ülejäänud sõltumatud muutujad on konstantsed). Tunnuse INSTSCIE (motivatsioon teaduse õppimiseks) regressioonikordaja on mingil põhjusel negatiivne (-11.315). Kui see muutuja suureneb ühe punkti võrra, langeb testiskoor umbes 11.3 punkti võrra.</p>
<p>Kõigi prediktorite kohta on ära toodud standardvead (tulbas <strong>Std. Error</strong>), t-statistikud (regressioonikordaja jagatud standardveaga) ning p-väärtused, mille abil saame otsustada, kas tegemist on statistiliselt usaldusväärse prediktoriga. P-väärtustest näeme, et kõik prediktorid on statistiliselt olulised.</p>
<p>Teades mudeli parameetrite väärtusi saaksime vajadusel kirja panna muutujate-vahelisi seoseid väljendava regressioonivõrrandi (ümmardades parameetrid ühe komakohani):</p>
<p><span class="math display">\[loodusteaduste testi skoor = 533.688 + 22.028 * teaduse nautimine + 8.895 * huvi teaduse vastu -11.315 * motivatsioon õppida teadust\]</span></p>
</div>
</div>
<div id="prediktorite-vordlemine" class="section level1">
<h1>Prediktorite võrdlemine</h1>
<div id="standardiseeritud-regressioonikordaja-ehk-beeta-kordaja" class="section level3">
<h3>Standardiseeritud regressioonikordaja ehk beeta-kordaja</h3>
<p>Prediktorite olulisuse võrdlemiseks kasutatakse sageli standardiseeritud regressioonikordajad ehk niinimetatud beeta-kordajad. Need ütlevad, mitme standardhälbe võrra muutub sõltuv muutuja, kui prediktor muutub ühe standardhälbe võrra (ja ülejäänud prediktorid jäävad samaks).</p>
<p>Standardhälbe ühikute kasutamine muudab eri muutujate kordajad otseselt võrreldavaks, kuna neid ei mõjuta see, kui prediktoreid on mõõdetud erinevates ühikutes. R-is saame need kätte lisamooduli <em>QuantPsyc</em> funktsiooni <em>lm.beta</em> abil, millele anname mudeli nime. Kasutamiseks tuleks kõigepealt see lisamoodul installida…</p>
<pre class="r"><code>install.packages(&quot;QuantPsyc&quot;)</code></pre>
<p>…ja laadida.</p>
<pre class="r"><code>library(QuantPsyc)
lm.beta(pisa.mudel2)</code></pre>
<pre><code>##    JOYSCIE    INTSCIE   INSTSCIE 
##  0.2352053  0.0830043 -0.1110762</code></pre>
<p>Näeme, et JOYSCIE <strong>beeta-kordaja</strong> on umbes 0.24 ja teiste muutujate omad 0.10-kanti. (Mõju suuruse võrdlemisel on oluline kordaja absoluutväärtus, miinusmärk INSTSCIE kordaja ees näitab mõju suunda.) Seega võime öelda, et JOYSCIE mõju loodusteaduste alatesti skoorile on laias laastus 3 korda suurem kui kahel ülejäänud muutujal.</p>
</div>
<div id="usalduspiirid" class="section level3">
<h3>Usalduspiirid</h3>
<p>Veel üks näitaja, mida regressioonikordajate kvaliteedi uurimiseks suhteliselt sageli kasutatakse on 95%-usalduspiirid. R-is saame need funktsiooni <em>confint</em> abil, millele anname mudeli nime</p>
<pre class="r"><code>confint(pisa.mudel2)</code></pre>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) 531.399676 535.976808
## JOYSCIE      18.769257  25.286657
## INTSCIE       5.300366  12.488963
## INSTSCIE    -14.564175  -8.066339</code></pre>
<p>95%-usalduspiirid tähendavad, et kui meil oleks ühe valimi asemel 100 valimit, siis 95-l juhul langevad mudeli parameetrite väärtused piiride vahemikku. Mida kitsam parameetri usaldusvahemik, seda parem. Samuti tahame, et prediktori usalduspiirid jääksid ühele poole nullpunkti. Kui nullpunkt jääb usaldusvahemiku sisse tähendab see, et mõnedes valimites oleks prediktori mõju positiivse ja teistes negatiivse suunaga. Kõigi prediktorite vahemikud üsna kitsad ja samasuguse suurusega. Võime eeldada, et mõnes teises samalaadses valimis on oodata üsna samasuguseid regressioonikordajajaid. Ka ei ületa ühegi muutuja usalduspiirid nullpunkti ja seega võib neid pidada usaldusväärseteks.</p>
</div>
<div id="ulesanne---mitmene-regressioon" class="section level3">
<h3>Ülesanne - mitmene regressioon</h3>
<ol style="list-style-type: decimal">
<li>Koostage uus mudel, milles sõltuvaks tunnuseks on matemaatika testi skoor (PVMATH) ja prediktoriteks samad tunnused, millega ülal ennustasime loodusteaduste testi skoori: teaduse oluliseks pidamine (JOYSCIE), huvi teaduse vastu (INTSCIE) ja motivatsioon loodusteadusi õppida (INSTSCIE). Missugused prediktorid on statistiliselt olulised? Arvutage ka standardiseeritud regressioonikordajad ja mudeli parameetrite usalduspiirid.</li>
</ol>
<pre class="r"><code>pisa.mudel4 = lm(PVMATH ~ JOYSCIE + INTSCIE + INSTSCIE, data = pisa)
summary(pisa.mudel4) #vaatame tulemusi</code></pre>
<pre><code>## 
## Call:
## lm(formula = PVMATH ~ JOYSCIE + INTSCIE + INSTSCIE, data = pisa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -294.553  -48.430   -0.031   50.209  215.068 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  516.405      1.104 467.678  &lt; 2e-16 ***
## JOYSCIE       15.741      1.572  10.011  &lt; 2e-16 ***
## INTSCIE       12.397      1.734   7.149 1.01e-12 ***
## INSTSCIE     -14.138      1.568  -9.019  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 72.93 on 4764 degrees of freedom
## Multiple R-squared:  0.05301,    Adjusted R-squared:  0.05242 
## F-statistic:  88.9 on 3 and 4764 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>library(QuantPsyc)
lm.beta(pisa.mudel4) #vaatame standardiseeritud regressioonikordajaid</code></pre>
<pre><code>##    JOYSCIE    INTSCIE   INSTSCIE 
##  0.1786851  0.1229927 -0.1475509</code></pre>
<pre class="r"><code>confint(pisa.mudel4) # arvutame regressioonikordajatele usalduspiirid</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) 514.240738 518.57018
## JOYSCIE      12.658190  18.82291
## INTSCIE       8.997099  15.79669
## INSTSCIE    -17.211161 -11.06495</code></pre>
</div>
</div>
<div id="hierarhiliste-mudelite-vordlemine" class="section level1">
<h1>Hierarhiliste mudelite võrdlemine</h1>
<p>Mudelid <em>pisa.mudel1</em> ja <em>pisa.mudel2</em> on hierarhilised.</p>
<pre class="r"><code>pisa.mudel1 &lt;- lm(PVSCIE ~ GENSCIE, data = pisa)
pisa.mudel2 &lt;- lm(PVSCIE ~ GENSCIE + INTSCIE, data=pisa)</code></pre>
<p>See tähendab, et <em>pisa.mudel2</em> on saadud <em>pisa.mudel1</em>-le prediktoreid lisades. Hierarhiliste mudelite puhul saame arvutada statistilise usaldusväärsuse sellele, kas teine mudel on esimesest parem ehk kas prediktorite lisamine tegi mudelit paremaks. Mitte-hierarhiliste mudelite puhul seda teha ei saa. Nt me ei saa niimoodi võrrelda mudelit pisa.mudel1 (PVSCIE ~ GENSCIE) mudeliga, milles prediktoriteks oleksid INTSCIE ja INSTSCIE ilma GENSCIE-ta (PVSCIE ~ INTSCIE + INSTSCIE). Mudelite võrdlemiseks kasutame R-i funktsiooni <em>anova</em>.</p>
<pre class="r"><code>anova(pisa.mudel1, pisa.mudel2)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: PVSCIE ~ PVMATH
## Model 2: PVSCIE ~ JOYSCIE + INTSCIE + INSTSCIE
##   Res.Df      RSS Df Sum of Sq F Pr(&gt;F)
## 1   4766  4746192                      
## 2   4764 28321232  2 -23575040</code></pre>
<p>Eelkõige peaksime vaatama väljundis oleva tabeli viimase rea kahte parempoolset tulpa, milles on ära toodud mudelite erinevuse <strong>F-suhe</strong> ja selle <strong>p-väärtus</strong>. P-väärtus on praegusel juhul 4.128e-06 ehk 4.12 * <span class="math inline">\(10^{-6}\)</span> ehk p &lt; 0.001. Seega on tõenäosus, et nii suur F-suhte väärtus on saadud ainult tänu juhusele alla 0.1%-i ja võime tõdeda, et teine mudel on esimesest oluliselt parem. Kuigi ilmselt suuresti tänu meie väga suurele valimile, mille puhul ka üsnagi väikesed erinevused on statistiliselt olulised.</p>
</div>
<div id="kovariatsioonanaluus-ancova" class="section level1">
<h1>Kovariatsioonanalüüs (ANCOVA)</h1>
<p>Regressioonanalüüsi matemaatiline põhimõte on dispersioonanalüüsi (ANOVA) omale väga sarnane. Pidevaid ja diskreetseid tunnuseid saab kasutada ka samas mudelis. Pidevaid tunnuseid nimetatakse sellisel puhul kovariaatideks ja kogu analüüsi kovariatsioonianalüüsiks (ANCOVA).</p>
<pre class="r"><code>model.1 = lm (PV1READ ~ Gender + ESCS, data=pisaV2)
library(car)
Anova(model.1, type = &quot;III&quot;) </code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: PV1READ
##               Sum Sq  Df  F value    Pr(&gt;F)    
## (Intercept) 21875691   1 4060.861 &lt; 2.2e-16 ***
## Gender        326518   1   60.613 2.364e-14 ***
## ESCS          373425   1   69.320 4.077e-16 ***
## Residuals    3959415 735                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="ulesanded" class="section level1">
<h1>Ülesanded</h1>
<ol style="list-style-type: decimal">
<li>Tehke mudel, kus sõltuvaks tunnuseks on matemaatika testi skoor (PVMATH) ja prediktoriteks teaduse oluliseks pidamine (GENSCIE), huvi teaduse vastu (INTSCIE) ja motivatsioon loodusteadusi õppida (INSTSCIE). Missugused prediktorid on statistiliselt olulised?</li>
</ol>
<pre class="r"><code>pisa.mudel4 = lm(PVMATH ~ JOYSCIE + INTSCIE + INSTSCIE, data = pisa)
summary(pisa.mudel4) #vaatame tulemusi</code></pre>
<pre><code>## 
## Call:
## lm(formula = PVMATH ~ JOYSCIE + INTSCIE + INSTSCIE, data = pisa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -294.553  -48.430   -0.031   50.209  215.068 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  516.405      1.104 467.678  &lt; 2e-16 ***
## JOYSCIE       15.741      1.572  10.011  &lt; 2e-16 ***
## INTSCIE       12.397      1.734   7.149 1.01e-12 ***
## INSTSCIE     -14.138      1.568  -9.019  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 72.93 on 4764 degrees of freedom
## Multiple R-squared:  0.05301,    Adjusted R-squared:  0.05242 
## F-statistic:  88.9 on 3 and 4764 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Arvutage ka standardiseeritud regressioonikordajad ja mudeli parameetrite usalduspiirid.</li>
</ol>
<pre class="r"><code>library(QuantPsyc)
lm.beta(pisa.mudel4) #vaatame standardiseeritud regressioonikordajaid</code></pre>
<pre><code>##    JOYSCIE    INTSCIE   INSTSCIE 
##  0.1786851  0.1229927 -0.1475509</code></pre>
<pre class="r"><code>confint(pisa.mudel4) # arvutame regressioonikordajatele usalduspiirid</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) 514.240738 518.57018
## JOYSCIE      12.658190  18.82291
## INTSCIE       8.997099  15.79669
## INSTSCIE    -17.211161 -11.06495</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Kas mudelil on probleeme multikollineaarsuseega? Kas mudeli jäägid on normaaljaotuslikud?</li>
</ol>
<pre class="r"><code>cor(pisa[,c(&quot;JOYSCIE&quot;, &quot;INTSCIE&quot;, &quot;INSTSCIE&quot;)])</code></pre>
<pre><code>##            JOYSCIE   INTSCIE  INSTSCIE
## JOYSCIE  1.0000000 0.5478250 0.4752691
## INTSCIE  0.5478250 1.0000000 0.4085926
## INSTSCIE 0.4752691 0.4085926 1.0000000</code></pre>
<pre class="r"><code>describe(pisa.mudel4$residuals)</code></pre>
<pre><code>##    vars    n mean    sd median trimmed   mad     min    max  range  skew
## X1    1 4768    0 72.91  -0.03    0.41 72.98 -294.55 215.07 509.62 -0.09
##    kurtosis   se
## X1    -0.06 1.06</code></pre>
</div>
<div id="lisad" class="section level1">
<h1>LISAD</h1>
<div id="erindid" class="section level2">
<h2>Erindid</h2>
<pre class="r"><code>pisa.mudel2 &lt;- lm(PVSCIE ~ GENSCIE + INTSCIE + INSTSCIE, data=pisa)</code></pre>
<p>Seda, kas koostatud mudel sobib andmetega hästi, võib hinnata ka äärmuslike erindite abil. Erindid on need vaatlused (see tähendab andmeread, meie puhul vastajad), mis erinevad märkimisväärselt peamisest andmetes esinevast trendist. Sellised juhtumid leiame üles mudeli jääkide abil. (Jäägid mäletatavasti kujutasid endast tegelike andmete ja mudeli põhjal arvutatud väärtuste erinevust.) Tavapärased mudeli jäägid on samades ühikutes, milles on mõõdetud sõltuvat muutujad. Nende puhul on natuke raske otsustada, kui suurt jääki pidada suureks. Lihtsam on vaadata standardiseeritud jääke, mis on standardhälbe ühikutes. Kui selliste standardiseeritud jääkide osakaal, mille absoluutväärtus on üle kahe, on rohkem kui 5%, võib öelda, et mudel ei esinda meie andmeid väga hästi. Arvutame kõigepealt standardiseeritud jäägid funktsiooniga <em>rstandard</em> ja salvestame need muutujasse nimega <em>mud2.standardized.residuals</em>. (Kui selline pikk ja lohisev nimi ei meeldi, võib valida ka mõne lühema. Pikema nime eeliseks on aga, et selle abil on kergem aru saada, mis nime taga peitub.)</p>
<pre class="r"><code>mud2.standardized.residuals &lt;- rstandard(pisa.mudel2)</code></pre>
<p>Nüüd peame teada saama, kui palju on jääke absoluutväärtusega üle kahe. Absoluutväärtused saame funktsiooni <em>abs</em> abil, paneme nende kõrvale tingimuse (&gt; 2) ja selle kõige ümber funtsiooni sum, mis loeb kokku, palju on sellele tingimusele vastavaid jääke.</p>
<pre class="r"><code>sum(abs(mud2.standardized.residuals) &gt; 2)</code></pre>
<pre><code>## [1] 208</code></pre>
<p>Selliseid jääke on 208. Otsustamaks, kas see on rohkem kui 5%, peame teadma oma andmestiku suurust ehk tabeli pisa ridade arvu ja korrutama selle 0.05-ga. Ridade arvu saab kas RStudio Environment-paneelist (üleval paremal) või funktsiooni <em>nrow</em> abil.</p>
<pre class="r"><code>nrow(pisa) * 0.05</code></pre>
<pre><code>## [1] 238.4</code></pre>
<p>5 protsenti on antud juhul 238 ja kuna suuri jääke oli 208, võime järeldada, et neid on alla kriitilise piiri. Standardiseeritud jäägid absoluutväärtusega üle 3-e aitavad, meil üles leida vaatlused, millele koostatud mudel kohe üldse ei sobi. Selliste vaatluste arvu saame taas kasutades funktsioone sum ja abs.</p>
<pre class="r"><code>sum(abs(mud2.standardized.residuals) &gt; 3)</code></pre>
<pre><code>## [1] 10</code></pre>
<p>Nii suuri jääke on 10. Selliseid äärmuslikke erindeid tasuks reeglina lähemalt uurida. Need saame tabelist kätte kasutades tabeli nime, nurksulge ja tingimust, millele meid huvitavad read vastama peavad.</p>
<pre class="r"><code>pisa[abs(mud2.standardized.residuals) &gt; 3, ]</code></pre>
<pre><code>##         X   PVMATH   PVREAD   PVSCIE GENSCIE INSTSCIE INTSCIE JOYSCIE
## 53     53 676.8111 590.1395 722.9844 -1.6486  -0.4167 -0.5440 -0.8455
## 1797 1797 301.6747 216.5256 279.2202 -0.3580   0.7257  0.0663 -0.1028
## 2733 2733 709.9938 601.6094 767.2769  0.0792   1.8212  1.9779  2.0562
## 3135 3135 693.1687 665.8147 778.0936  0.4867   0.0195  0.6732  0.1728
## 3308 3308 284.6939 286.6283 314.4677  0.4867   0.7257  0.2143 -0.3437
## 3393 3393 253.6922 275.1020 308.3133  0.4867   0.9603  0.6732  0.8776
## 3447 3447 251.5890 218.4506 250.7797  0.4867   1.1694  1.2778  0.1728
## 4052 4052 315.3840 252.2988 299.3616  0.8962   0.9603  1.4176  0.1728
## 4645 4645 375.4401 331.1444 394.7537  2.1867   0.3719  3.2888  0.8776
## 4702 4702 387.3578 354.3248 370.3228  2.1867   1.1694  1.0131 -0.8455
##      PERSCIE SCIEEFF SCIEFUT  SCSCIE GR GENDER
## 53   -0.8110 -0.3985 -0.0492 -0.8207  9      M
## 1797  0.7259 -0.3985 -0.0492 -0.5445  7      M
## 2733  2.5264  3.2230  1.8262  2.2442  9      M
## 3135  1.0558  0.5179  0.8285  2.2442  9      F
## 3308  0.7259 -0.5654 -0.0492 -0.8207  8      M
## 3393  1.3959 -0.0337  0.8285  1.2090  8      F
## 3447  0.3867  0.1288  1.5467  1.3981  8      M
## 4052  0.7259 -0.7309  1.5467  1.3981  9      M
## 4645  2.5264  1.2058  1.3025  1.3981  9      M
## 4702  2.5264 -0.2283 -0.0492 -0.8207  9      M</code></pre>
<p>Antud juhul on tegemist meile üsna võõra andmestikuga ja me ei oska täpselt öelda, mis erindite põhjuseks võib olla. Kui me aga juhtume töötama andmetega, mida lähemalt tunneme, oskame paremini hinnata, kas nende puhul on midagi kahtlast, mis on kaasa toonud selle, et need juhtumid mudeliga hästi ei sobi. Samas ei tohiks suurte jääkidega vaatlusi väga kergekäeliselt välja visata, vaid ainult siis, kui tegemist on ilmselgelt kahtlaste asjaoludega (nt näpuviga andmete sisestamisel). Praegu on meil tegemist suure valimiga ning erindid väljenduvad peamiselt selles, et mudel nende kirjeldamiseks hästi ei sobi. Väiksemate valimite puhul võib ette tulla vastupidine olukord: üks teistest selgelt eristuv väärtus hakkab kallutama mudelit enda suunas. Kuna sellised vaatlused on väga mõjukad ja kallutanud mudeli endale vastavamaks, ei pruugi nende jääk olla üldsegi suur. Samas ei pruugi mudel andmetega hästi sobida, sest ülejäänud omavahel sarnasemate vaatluste jäägid on selle tõttu omakorda suurenenud. Selliste mõjukate juhtumite avastamiseks saab kasutada näitajaid, mida nimetatakse <strong>Cooki kaugusteks</strong> ning mille puhul annavad <strong>ühest suuremad väärtused</strong> põhjust kõrgendatud tähelepanuks. Need näitajad saame arvutada funktsiooni <em>cooks.distance</em> abil, millele anname ette mudeli. Kasutame seda praegu koos funktsiooniga <em>max</em>, et leida, kui suur on meie mudeli puhul kõige suurem Cooki kaugus.</p>
<pre class="r"><code>max(cooks.distance(pisa.mudel2))</code></pre>
<pre><code>## [1] 0.01945075</code></pre>
<p>See on umbes 0.02, mis jääb ühest üsna kaugele, järelikult liigselt mõjukate juhtumitega meil praegu probleeme pole (nagu oodata oligi). Kui meil esineks selliseid juhtumeid saaksime need kätte nii:</p>
<pre class="r"><code>pisa[cooks.distance(pisa.mudel2) &gt; 1,]</code></pre>
<pre><code>##  [1] X        PVMATH   PVREAD   PVSCIE   GENSCIE  INSTSCIE INTSCIE 
##  [8] JOYSCIE  PERSCIE  SCIEEFF  SCIEFUT  SCSCIE   GR       GENDER  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<p>Kuna meil selliseid juhtumeid polnud, siis pragusel juhul saime tagasi tühja tabeli, milles 0 rida. Juhul kui meil mõjukaid juhtumeid esineb ja tahame mudelit korrata ilma nendeta, saab seda teha andes funktsioonile lm argumendi subset abil tingimuse, mille alusel vaatlusi mudelist välja jätta. Paigutame kõigepealt Cooki kaugused muutujasse nimega <em>cooki.kaugused</em>. Seejärel teeme mudeli funktsioonga lm kasutades lisaargumenti subset, mille abil kaasame ainult vaatlused, mille puhul on Cooki kauguse väärtus alla ühe.</p>
<pre class="r"><code>cooki.kaugused &lt;- cooks.distance(pisa.mudel2)</code></pre>
<pre class="r"><code>pisa.mudel3 &lt;- lm(PVSCIE ~ GENSCIE + INTSCIE + INSTSCIE,
data=pisa,
subset=cooki.kaugused&lt;1)</code></pre>
<p>See koodijupp oli ainult näitlikustamiseks, kuna meil praegu suuri kaugusi ei esinenud, tuleb uus mudel täpselt samasugune kui <em>pisa.mudel2</em>.</p>
</div>
<div id="mudeli-uldistamise-eeldused" class="section level2">
<h2>Mudeli üldistamise eeldused</h2>
<p>Enamasti tahame oma analüüsi tulemusi üldistada <span class="math inline">\(-\)</span> teha järeldusi mitte ainult oma valimi, vaid mingite suuremate inimrühmade või muu taolise kohta. Selleks peab olema täidetud rida eeldusi. Ka eelduste täitmisel võib juhtuda, et kui mudelit korrata suurema valimiga, saame teistsuguse tulemuse, aga vähemalt suurendab see sarnase tulemuse tõenäosust. Kui eeldusi rikutakse, pole mudeli üldistamine korrektne, küll saame jätkuvalt öelda, et tulemused kehtivad valimi kohta, mille põhjal me mudeli koostasime.</p>
</div>
<div id="multikollineaarsus" class="section level2">
<h2>Multikollineaarsus</h2>
<p>Üheks probleemiks, mis esineda võib, on multikollineaarsus ehk olukord, kui mudeli prediktorid on omavahel liiga tugevalt korreleeritud. Multikollineaarsuse esinemine suurendab regressioonikordajate standardvigasid, mis tähendab, et need on vähem usaldusväärsed ja seetõttu on tõenäosus saada samasuguseid kordajaid teistes valimites väiksem. Probleemse multikollineaarsuse avastamiseks võime vaadata prediktorite-vahelisi korrelatsioone. Need saame andes funktsioonile <em>cor</em> meid huvitavad tabeli tulbad.</p>
<pre class="r"><code>cor(pisa[,c(&quot;GENSCIE&quot;, &quot;INTSCIE&quot;, &quot;INSTSCIE&quot;)])</code></pre>
<pre><code>##            GENSCIE   INTSCIE  INSTSCIE
## GENSCIE  1.0000000 0.3088645 0.2506105
## INTSCIE  0.3088645 1.0000000 0.4085926
## INSTSCIE 0.2506105 0.4085926 1.0000000</code></pre>
<p>Saame tagasi korrelatsioonimaatriksi. Problemaatilised on muutujatevahelised korrelatsioonid absoluutväärtusega &gt; 0.8. Kui selliseid esineb, tasuks üks tugevalt korreleeritud muutujatest mudelist välja jätta.</p>
<p>Praegu on tugevaim korrelatsioon umbes 0.4 (INTSCIE ja INSTSCIE vahel). Veel üks näitaja, mis aitab multikollineaarsust avastada on muutujate variatsiooniindeksid, mille abil saame funktsiooni <em>vif</em> abil, andes sellele ette mudeli nime. See tuleb lisamoodulist <em>car</em>, mille peame eelnevalt installima.</p>
<pre class="r"><code>install.packages(&quot;car&quot;)</code></pre>
<p>Nüüd saame mooduli laadida ja kasutada funktsiooni <em>vif</em>.</p>
<pre class="r"><code>library(car)
vif(pisa.mudel2)</code></pre>
<pre><code>##  GENSCIE  INTSCIE INSTSCIE 
## 1.128639 1.269734 1.225578</code></pre>
<p>Indeksi väärtused üle 10-e annavad märku probleemsest multikollineaarsusest. Praegusel juhul selliseid väärtusi ei esine.</p>
</div>
<div id="heteroskedaktilisus" class="section level2">
<h2>Heteroskedaktilisus</h2>
<p>Teine keerulise nimega probleem, mis võib takistada mudeli järelduste üldistamist on heteroskedaktilisus ehk olukord kui mudeli jääkide hajuvus on prediktorite eri tasemetel liiga erinev. Nähtuse esinemist saame uurida hajuvusdiagrammi abil, mille ühel teljel on mudeli jäägid (saame funtksioon resid abil) ja teisel teljel mudeli poolt ennustatud väärtused (need saame funktsiooni fitted.values abil).</p>
<pre class="r"><code>library(ggplot2)
plot(fitted.values(pisa.mudel2), resid(pisa.mudel2))</code></pre>
<p><img src="praktikum4v2_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>Joonisel olev punktikogum peaks olema ühtlane, see ei tohiks olla lehtrikujuline ehk ühes servast märkimisv äärselt kitsam kui teises servas. Antud juhul see enam-vähem nii ongi. Silma hakkavad üksikud eristuvad andmepunktid (see on suure valimi puhul oodatav), aga mitte midagi süstemaatilist. (Lisaks sellele: kui antud joonisel ilmneb U-kujuline muster, viitab see, et muutujate vaheline seos pole päris lineaarne.)</p>
</div>
<div id="jaakide-normaaljaotus" class="section level2">
<h2>Jääkide normaaljaotus</h2>
<p>Kolmas üldistamise eeldus, mida alguses põgusalt mainitud sai, on, et mudeli jäägid peavad olema normaaljaotusega.</p>
<p>Sellest annab aimu mudeli jääkide histogramm.</p>
<pre class="r"><code>hist(mud2.standardized.residuals)</code></pre>
<p><img src="praktikum4v2_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Teist tüüpi joonis, mille abil jääkide normaaljaotusele vastavust uurida on niinimetatud tõenäosuspaber ehk kvantiil-kvantiil diagramm (ingl. k. <em>Q-Q plot</em>). Selle saame kasutades funktsioone <em>qqnorm</em> ja <em>qqline</em> ja andes neile ette mudeli jäägid.</p>
<pre class="r"><code>qqnorm(mud2.standardized.residuals)
qqline(mud2.standardized.residuals, col=&quot;red&quot;, lwd=2)</code></pre>
<p><img src="praktikum4v2_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>Sirge joon esindab normaaljaotust ja punktid jääke. Täiusliku normaaljaotuse korral oleksid kõik punktid joone peal. Kõrvalekalded joonest on tavalised otstes, kuid keskel ei tohiks tohiks neid esineda. Praegu me midagi sellist näemegi; otstes on väikesed kõrvalekalded, aga mitte midagi hullu silma ei hakka.</p>
</div>
<div id="jaakide-soltumatus" class="section level2">
<h2>Jääkide sõltumatus</h2>
<p>Veel üks jääke puudutav mudeli üldistamise eeldus on jääkide sõltumatus, mis tähendab, et ei tohi esineda liiga palju üksteisega sarnanevaid jääke. Seda eeldust saab kontrollida <strong>Durbin-Watsoni testi</strong> abil, mille saame lisamoodulis <em>car</em> paikneva funtsiooni <em>dwt</em> abil, millele anname ette mudeli-objekti. (Kuna eelnevalt selle mooduli installisime ja laadisime pole seda praegu enam vaja teha.)</p>
<pre class="r"><code>dwt(pisa.mudel2)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1      0.04833149      1.902115       0
##  Alternative hypothesis: rho != 0</code></pre>
<p>Vaatame väljundis numbrit, mille kohale on kirjutatud <strong>D-W Statistic</strong>. Selle soovitav väärtus on vahemikus 1 kuni 3, mida lähemal 2-le, seda parem. Antud juhul statistiku väärtuseks 1.9, mille põhjal võime järeldada, et meil pole jääkide sõltumatusega probleeme.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
