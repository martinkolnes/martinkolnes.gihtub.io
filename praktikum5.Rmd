---
title: "Logistiline regressioon"
author: "Martin Kolnes, Karin Täht"
output:
  html_document:
    css: style.css
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
  word_document:
    toc: yes
---

Laadige alla [praktikumi andmed](https://drive.google.com/open?id=1JlHhXSz-B8wejK43wo231dK--WUv6WgJ).  
```{r, echo = F}
neeme <- read.csv("KMKT/5praktikum/neeme.csv")[,-1]
cowles <- read.csv("KMKT/5praktikum/cowles.csv")[,-1]
ESS <- read.csv("KMKT/5praktikum/ESS.csv")[,-1]
pisa <- read.csv("KMKT/5praktikum/pisa.csv")[,-1]
```

# Kordamine
1. Tehke PISA andmestiku alusel regressioonanalüüs, kus sõltuvaks tunnuseks on  matemaatika testi tulemus (PVMATH) ja prediktoriteks enese-tõhusus teaduses (SCIEEFF; *science self-efficacy*) ja mina-pilt loodusteadustes (SCSCIE; *science self-concept*).

```{r, echo = FALSE, eval = F}
model.yl1 <- lm(PVMATH ~ SCIEEFF + SCSCIE, data = pisa)
summary(model.yl1)
```
2. Arvutage ka standardiseeritud regressioonikordajad ja mudeli parameetrite usalduspiirid.
```{r, eval = F, echo =F}
library(QuantPsyc)
lm.beta(model.yl1)
confint(model.yl1)
```

3. Kas mudeli jäägid jaotuvad normaalajaotusel vastavalt?
```{r, eval = F, echo =F}
hist(model.yl1$residuals)
library(psych)
describe(model.yl1$residuals)
```

# Logistiline regressioon  
Kui lineaarse regressiooni puhul oli sõltuv tunnus numbriline, siis logistilise regressiooni puhul on sõltuv tunnus kategoriaalne. Logistiline mudel ennustab prediktorite väärtuste abil võimalust kuuluda mingisse kategooriasse. Binaarne logistiline regressioon on selline, mille puhul on sõltuval tunnusel ainult 2 taset (nt kas inimesel esineb konkreetne haigus või mitte). Multinomiaalse logistilise regressiooni puhul on sõltuva muutuja tasemeid rohkem kui 2.

# Binaarne logistiline regressioon - ühe prediktoriga mudel  

Andmetabel nimega "cowles" käsitleb seost tudengite isiksuseomaduste ja psühholoogilistes uurimustes osalemise valmiduse vahel. Andmestik koosneb neljast muutujast:

* *neuroticism* - Eysencki isiksuseküsimustku neurootilisuse alaskaala skoor;
* *extraversion* - ekstravertsuse alaskaala skoor;
* *sex* - sugu (*female*, *male*);
* *volunteer* - kas tudeng on valmis osalema edasises uurimistöös (*no*, *yes*);

Esmase ülevaate saamiseks andmetest kasutage funktsiooni *summary*. 
```{r}
summary(cowles)
```


Teeme kõigepealt logistilise regressioonmudeli, milles sõltuvaks tunnuseks on valmidus osaleda uurimistöös (tunnus *volunteer*) ja ennustame seda ekstravertsuse skoori kaudu. Logistilise mudeli tegemiseks kasutame funktsiooni *glm* (*generalized linear model*). Selle funktsiooni kasutamine on sarnane eelmises praktikumis kasutatud *lm* funktsiooniga. Kõigepealt peame sisestama mudelisse kaasatavate muutujate nimed ("sõltuv tunnus ~ sõltumatu tunnus") ning seejärel andmestiku nime ("data = andmestik"). Funktsiooni *glm* puhul lisandub argument *family*, mille abil määrame, millist tüüpi mudelit teha tahame. Logistilise mudeli puhul paneme argumendi *family* väärtuseks *binomial()*. (Kui meil juhtub esinema puuduvaid andmeid, saame need välja jätta lisades argumendi *na.action=na.omit*. Samuti saaksime argumendi *subset* abil määrata valimit kitsendava tingimuse.)


```{r}
cowles.mudel1 <- glm(volunteer ~ extraversion, data=cowles, family=binomial())
```

Uurime mudeli väljundit.

```{r}
summary(cowles.mudel1)
```
  
  
Vaatame väljundi alaosa nimega **Coefficients**. Tulbas **Estimate** on ära toodud mudeli parameetrite - vabaliikme (*Intercept*) ja regressioonikordaja - väärtused. Tulbas **Std. Error** on ära toodud standardviga (kui suurt kordaja kõikumist võib oodata erinevates valimites). Tulbas **z value** on toodud z-statistiku väärtus, mis on tuntud ka *Waldi* statistiku nime all. See on saadud jagades regressioonikordaja väärtuse ja standardvea omaga. **Tulbas Pr(>|z|)** on märgitud z-statistiku kaudu arvutatud p-väärtus, mille abil saame hinnata, kas prediktor omab olulist seost sõltuva muutujaga. Praegusel juhul on ekstravertsuse regressioonikordajale vastav p-väärtus $3.49e-06$ ehk $3.49 * 10^{-6}$. Antud
prediktori olulisusele nivool p < .001 viitavad ka rea lõpus olevad 3 tärni.  

## Riskisuhte arvutamine
Logistilise regressiooni puhul on regressioonikordajad logaritmskaalal ja sellisel kujul on nende tõlgendamine üsna keeruline. Olukord läheb paremaks, kui teisendame regressioonikordaja eksponent-funktsiooni abil (logaritmimise pöördfunktsioon). Selle tulemusel saadud arve nimetatakse **riskisuheteks** või ka **šansside suheteks**. Riskisuhete saamiseks kasutame funktsioone *coef* ja *exp*. Funktsioonile *coef* anname argumendiks mudeli nime. See funktsioon eraldab mudelist ainult mudeli parameetrite väärtused. Funktsioonile *exp* anname argumendiks funktsioonist *coef* saadud väärtused. R-is saame teha seda hierahriliselt:  

```{r}
exp(coef(cowles.mudel1))
```

**Kuidas riskisuhteid tõlgendada?** 1-st suurem riskisuhte väärtus näitab, et prediktori väärtuse suurenedes ühe ühiku võrra suurenevad sündmuse esinemise  šansid nii mitu korda kui on riskisuhte väärtus. 1-st väiksem riskisuhte väärtus näitab, et prediktori väärtuse suurendes ühe ühiku võrra sündmuse esinemise  šansid vähenevad 1/riskisuhe korda. Antud juhul on ekstravertsuse riskisuhte väärtuseks ümmardatuna 1.068. See tähendab, et kui ekstravertsuse skoor suureneb ühe punkti võrra suureneb jaatava vastuse tõenäosus 1.068 korda ehk 6.8\% võrra.  
Kuidas me teame, et need on just jaatava (ja mitte eitava) vastuse  šansid? Vaikimisi käivad numbrid selle sõltuva muutuja taseme kohta, mille nimetus paikneb tähestikulises järjekorras tagapool (eespool paiknev kategooria on valitud taustkategooriaks). Antud juhul oli meie sõltuval muutujal "volunteer" 2 taset: *no* ja *yes*. Kuna *yes* algustäht paikneb tähestikus tagapool on praegusel juhul just see, mille  šansse numbrid näitavad.

## Riskisuhte usaldusvahemikud  
Lineaarse regressiooni puhul nägime, et üheks täiendavaks võimaluseks hinnata prediktorite mõju usaldusväärsust olid regressioonikordajate 95\% -usaldusvahemikud. Sedasama lähenemist saame kasutada ka logistilise regressiooni puhul, arvutades usaldusvahemikud riskisuhete jaoks. Usaldusvahemikud saime funktsiooni *confint* abil. Logistilise regressiooni puhul lisame veel funktsiooni *exp* (logaritmimise pöördfunktsioon).

```{r}
exp(confint(cowles.mudel1))
```

Riskisuhte usaldusintervallide puhul on oluline vaadata, kas väärtus 1 jääb usaldusintervalli sisse. Kui nii juhtub, viitab see sellele, et prediktori mõju pole usaldusväärne: mõnedes valimites oleks mõju suund ühesugune ja teistes valimites teistsugune. Antud juhul on ekstravertsuse mõlemad usalduspiirid ühest suuremad. Seega võime olla üsna kindlad, et ekstravertsus mõjutab uurimustes osalemise valmidust positiivselt. 

## Hii-ruut test

Regressioonikordajad, riskisuhted ja nende usaldusvahemikud iseloomustavad eraldiseisvaid prediktoreid. Lisaks sellele on mudeli väljundis toodud ka mudeli sobitusastme näitajad. Mudeli jääkhälbimus (*Residual deviance*) iseloomustab meie koostatud mudeli logaritmilise tõepärafunktsiooni väärtust. Viimane põhineb mudeli järgi ennustatud ja tegelike väärtustega seotud tõenäosuste summeerimisel. Mida parem mudel, seda väiksem väärtus. Väljundis toodud **Null Deviance** on sama näitaja ainult vabaliiget sisaldava mudeli jaoks, milles muutujate vaheline seos puudub (nn nullmudel). Kui **Residual deviance** on väiksem kui **Null deviance**, tähendab see, et koostatud mudel on parem kui nullmudel. Selle üle, kas erinevus nullmudelist on piisavalt suur, saab otsustada  ${\chi}^2 -$testi (hii-ruuttesti) abil. Mingil põhjusel funktsioon *glm* seda välja ei arvuta ja meil tuleb seda ise teha funktsiooni *anova* abil. Defneerime kõigepealt ilma prediktoriteta ainult vabaliiget sisaldava nullmudeli.   
Selle valem on kujul: "sõltuv muutuja ~ 1".

```{r}
cowles.nullmudel <- glm(volunteer ~ 1, data=cowles, family=binomial())
```


Nüüd võrdleme nullmudelit ja eelnevalt koostatud mudelit anname *anova* funktsiooniga. Argumendi *test=“Chisq”* abil anname teada, et tahame kasutada hii-ruut testi.
```{r}
anova(cowles.nullmudel, cowles.mudel1, test="Chisq")
```

Vaatame tabeli teise rea kahte viimast tulpa, milles on toodud hii-ruut statistik (*Deviance*), ja selle p-väärtus. Antud p-väärtuse põhjal võime öelda, et mudeli sobitusaste oli nullmudeli omast oluliselt parem (${\chi}^2$ = 22.02, p < .001). 

## Pseudo-determinatsioonikordaja

Lineaarse regressiooni puhul saime välja arvutada mudeli determinatsioonikordaja($R^2$), mis näitas kui suure osa sõltuva tunnuse hajuvusest mudel ära kirjeldas. Logistilise regressiooni puhul saame arvutada näitajaid, mida nimetatakse pseudo-determinatsioonikordajaks. Need varieeruvad samuti 0-st 1-ni ja näitavad mudeli sobitustusastme headust (mida suurem väärtus seda parem). Sõltuvalt arvutuskäigust on pseudo-determinatsioonikordajaid mitut tüüpi. Arvutame praegusel juhul ühe sagedamini kasutatava, mida nimetatakse Nagelkerke $R^2$. Selle jaoks peame kõigepealt installima lisamooduli *fmsb*.

```{r, eval = F, message= F, warning=F}
install.packages("fmsb")
```

Seejärel saame lisamooduli laadida ja kasutada selles olevat funktsiooni *NagelkerkeR2*:
```{r}
library(fmsb)
NagelkerkeR2(cowles.mudel1)
```


**Pseudo-determinatsioonikordaja** väärtused ongi tüüpiliselt üsna madalad. Kordajat kasutatakse tüüpiliselt selleks, et hinnata, kas prediktorite lisamine tegi mudelit paremaks.  


## Standardiseeritud skooride kasutamine

Eelnevalt kasutasime mudelis ekstravertsuse toorskoore, mis teeb tulemuste tõlgendamise keeruliseks. See tähendab, et me ei oska eriti täpselt hinnata, kas ühe-punktiline muutus ekstravertsuse skooris on suur või väike. Seetõttu on vahepeal mõistlik numbriline prediktor kaasata standardiseerituna ehk standarhälbe ühikutesse teisendatuna. Sel juhul saame riskisuhteid tõlgendades öelda, et prediktori muutudes ühe standardhälbe võrra muutuvad huvipakkuva sündmuse esinemise šanssid nii mitu korda.   
Prediktori saame standardiseerida funktsiooniga *scale()*:
```{r}
cowles.mudel1 <- glm(volunteer ~ scale(extraversion), data=cowles, family=binomial())
exp(coef(cowles.mudel1))
```

Võime järeldada, et ekstravertsuse suurenedes ühe standardhälbe võrra suureneb uurimustes osalemise valmidus 1.29 korda ehk 29\% võrra.  


# Binaarne logistiline regressioon - kahe prediktoriga mudel  

Mudelitesse saab prediktorina kaasata ka kategoriaalseid muutujaid. Teeme uue mudeli, lisades täiendava pretiktorina vastaja soo (tunnus *sex*) ja uurime mudeli väljundit.
```{r}
cowles.mudel2 <- glm(volunteer ~ scale(extraversion) + sex, data=cowles, family=binomial())
summary(cowles.mudel2)
```


Tabelist **Coefficients** näeme p-väärtuste abil, et mõlemad prediktorid on olulised. Kategoriaalsete muutujate puhul valitakse üks kategooriatest baaskategooriaks, millega ülejäänud kategooriaid võrreldakse. Praegusel juhul on muutujal *sex* kaks taset (*female* ja *male*). Vaikimisi on baaskategooriaks valitud *female*, tulenevalt sellest, et *female* on tähestukuliselt eespool võrreldes *male*'iga. Seega näitab vastav regressioonikordaja, kui erinev on kategooria *male* võrreldes kategooriaga *female*. Miinusmärgist selle kordaja ees võime järeldada, et meeste puhul on jaatava vastuse tõenäosus naistega võrreldes madalam. Kordajate arusaadavamaks tõlgendamiseks arvutame neist jällegi riskisuhted.
```{r}
exp(coef(cowles.mudel2))
```

Ekstravertsuse riskisuhe on jäänud samaks. Vastaja soo riskisuhtest võime järeldada, et meeste puhul on jaatava vastamise tõenäosus 78\% naiste jaatava vastuse tõenäosusest. Ehk naiste puhul jaatava vastuse tõenäosus $1/0.78 = 1.28$ korda suurem kui meeste puhul. 

Hindame prediktoreid ka 95\%-usaldusvahemike abil.
```{r}
exp(confint(cowles.mudel2))
```

Nagu näha ei sisalda kummagi prediktori vahemikud väärtust 1 ja sellest tulenevalt võib neid lugeda usaldusväärseteks.

Arvutame mudeli pseudo-determinatsioonikordaja.
```{r}
NagelkerkeR2(cowles.mudel2)
```


See on jäänud enam-vähem samaks, nii et soo lisamine mudeli kirjeldusvõimet väga palju paremaks ei teinud. 


# Multinomiaalne logistiline regressioon   
Vaatame põgusalt ka logistilist regressiooni sõltuva muutuja korral, millel on rohkem kui kaks taset. Kasutame selleks paketi *nnet* funktsiooni *multinom()*. 

```{r, eval = F}
install.packages("nnet") # installeerime paketi
```

```{r, warning= F, message=F}
library(nnet) 
```

Andmetabelis ESS on 4 muutujat 2008. aasta Euroopa Sotsiaaluuringu Eesti vastajaid puudutavatest andmetest. üks tunnustest puudutab seda, millise erakonna poolt hääletas vastaja viimastel valimistel (tunnus *partei*). Näitlikustamise lihtsuse huvides olen antud tabelisse alles jätnud ainult 3 valimis kõige suuremat toetust omavat parteid (IRL, Kesk ja Reform). Teeme mudeli, milles ennustame erakondlikku eelistust vastaja vanuse kaudu.  Vaikimisi võetakse baaskategooriaks tähestiku järjekorras kõige esimene kategooria, antud juhul oleks selleks IRL. (Baaskategooria saab muuta funktsiooni *relevel* abil.)  

```{r}
ess.mudel1 <- multinom(partei ~ vanus, data = ESS)
```

Uurime tulemusi:
```{r}
summary(ess.mudel1)
```
Väljund on jaotatud kaheks osaks: regressioonikordajad ja standardvead. Regressioonikordajad on toodud kummagi partei jaoks eraldi. Nende põhjal on näha, et võrreldes IRL-iga suurendab kasvav vanus Keskerakonna poolt hääletamise tõenäosust, samas kui Reformierakonna toetamise tõenäosusega ei tundu seost olevat. 
Kahjuks ei anna multinom funktsioon meile p-väärtusi. Nende välja arvutamiseks on erinevaid viise, aga kõige lihtsam on kasutada paketi *stargazer* samanimelist funktsiooni, mis annab meile regressioonimudeli tulemused ja lisab sinna p-väärtused.
```{r, eval = F}
install.packages("stargazer")
```

```{r, warning= F, message=F}
library(stargazer)
stargazer(ess.mudel1, type="text", out="multi1.htm")
```

Vanuse mõju suurust saab hinnata riskisuhete abil:
```{r}
exp(coef(ess.mudel1))
```
Keskerakonna regressioonikordaja riskisuhte alusel võime järeldada, et lisanduv eluaasta suurendab Keskerakonna toetamise suhtelist tõenäosust võrreldes IRL-i toetamise tõenäosusega 1.02 korda ehk 2\%.


# Ülesanded

1. Andmetabelist nimega neeme on Marko Neeme magistritöö (Neeme, 2012) andmed, milles uuriti 50-70-aastaste meeste suhtumist eesnäärmevähi skriiningtesti. Tunnus ""valmidus", näitab testis osalemise valmidust (tasemed pigem jah, ja pigem ei). Lisaks on tabelis ära toodud Suure Viisiku isiksuseomadused: neurootilisus (tunnus N), ekstravertsus (E), avatus kogemusele (O), sotsiaalsus (A) ja meelekindlus (C). Koostage binaarse logistilise regressiooni mudel, mis ennustab skriiningtestis osalemise valmidust Suure Viisiku isiksuseomaduste kaudu.   

a. Esialgu tuleks saada ülevaade andmetest. Kasutage funktsiooni *summary*. Milline on oslejate keskmine vanus? Missugune on "valmiduse" jaotus?  
```{r, eval = F, echo =F}
summary(neeme)
prop.table(table(neeme$valmidus))*100#jaotus protsentides
```

b. Tehke ekstravertsuse tulemustest histogramm.
```{r, eval = F, echo =F}
library(ggplot2)
ggplot(neeme, aes(E))+
        geom_histogram()+
        theme_classic()+
        labs(x = "Ekstravertsus", y = "Kogus")
```

c.  Millised isiksusomadused omavad olulist seost valmidusega? Kas need omadused suurendavad või vähendavad testis osalemise valmidust?  
```{r, eval = F, echo =F}
mudel.yl2 <- glm(valmidus~N+E+O+A+C, data = neeme, family = binomial())
summary(mudel.yl2)
```

d.  Arvutage välja riskisuhted ja nende 95\%-usaldusvahemikud? Milline omadus mõjutab osalemisvalmidust kõige tugevamini?  
```{r, eval = F, echo =F}
round(exp(coef(mudel.yl2)),3)
round(exp(confint(mudel.yl2)),3)
```

e.  Arvutage mudeli sobitusastet näitav hii-ruut-statistik ja selle p-väärtus.  
```{r, eval = F, echo =F}
#Siin võis tekkid osadel probleem hii-ruudu arvutamisega. 
# Kui kustutate andmetest puuduvad andmed, siis peaks nende kahe mudeli võrdlus töötama:
neeme2 <- na.omit(neeme)#see rida loob uue andmestiku, kus ei ole NA'sid
#Nüüd teen mõlemad mudedlid selle uue andmestikuga:
mudel.yl2 <- glm(valmidus~N+E+O+A+C, data = neeme2, family = binomial())
mudel.yl2.null <- glm(valmidus~1, data = neeme2, family = binomial())
anova(mudel.yl2, mudel.yl2.null, test = "Chisq")
```

f.  Leidke mudeli pseudo-determinatsioonikordja.  
```{r, eval = F, echo =F}
NagelkerkeR2(mudel.yl2)
```


#LISAD
##Tingimuslik tihedusfunktsiooni joonis (conditional density plot)  
Kui meil on ühe numbrilise prediktoriga logistiline mudel (nagu praegu), siis saab vastavat seost kujutada tingimusliku tihedusfunktsiooni joonise abil. Selle saame funktsiooni *cdplot* kaudu.

```{r}
cdplot(volunteer ~ extraversion, data=cowles)
```

Joonisel on näha, milline on jaatavate ja eitavate vastuste osakaal valimis erinevate ekstravertsuse tasemete puhul. Heledam hall toon tähistab jaatava vastuse tõenäosust ja tumedam eitava vastuse oma.

## Vastuse tõnäosus prediktori konkreetse väärtuse korral  
Mudeli parameetrite abil saame välja arvutada ka, milline on jaatava vastuse tõenäosus mingil ekstravertsuse tasemel. Logistilise regressioonimudeli parameetrid on logaritmiliselt teisendatud \v{s}ansside kujul ehk keerulisemalt öeldes, vastavad tõenäosused on teisendatud logit-funktsiooni abil. Defineerime kõigepealt logit-funktsiooni pöördfunktsiooni expit, mille abil saame logaritmilised \v{s}anssid tagasi tõenäosusteks.

```{r}
expit <- function(x) exp(x) / (1+exp(x))
```

Seejärel küsime funktsiooni *coef* abil oma mudelist parameetrite väärtused.
```{r}
coef(cowles.mudel1)
```

Nüüd saame parameetrite väärtused anda funktsioonile *expit*. Seda tuleks teha sellisel kujul: kõigepealt vabaliikme väärtus, millele liidame otsa prediktori regressioonikordaja väärtuse korrutatuna meid huvitava prediktori taseme väärtusega. Kui sooviksime arvutada, milline on jaatava vastuse tõenäosus, kui ekstravertsuse skoor on 2 standardhälvet üle keskmise, näeks see välja nii.

```{r}
expit(-0.3275901 + 2*0.2554766)
```


Nagu näha, ennustab meie mudel sellisel juhul jaatava vastuse tõenäosuseks umbes 55\%.
