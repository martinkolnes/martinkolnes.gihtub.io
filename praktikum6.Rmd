---
title: 'Eksploratiivne faktoranalüüs'
author: "Martin Kolnes, Karin Täht"
output:
  html_document:
    css: style.css
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r, echo = F, eval = T}
load("KMKT/6praktikum/6praktikumAndmed.Rdata")
```
Laadige alla [praktikumi andmed](https://drive.google.com/open?id=1B7grF4qTJCmHU2QrKGaNrnxMurJb1Xce).  

# Faktoranalüüs ja peakomponentide analüüs
Nagu ilmselt teate, on olemas 2 lähedast meetodit: **faktoranalüüs** ja **peakomponentide analüüs**. Mõlema eesmärgiks on taandada suurem muutujatekogum väikseks arvuks liitmuutujateks. Sageli annavad mõlemad sarnase lõpptulemuse, kuid vahel võivad meetodite tulemused ka erineda. 

**Faktoranalüüsi** eesmärk on kirjeldada mingit suuremat hulka tunnuseid väiksema arvu hüpoteetiliste tunnuste ehk faktorite kaudu.  
**Peakomponentide analüüsi** eesmärk on välja selgitada väiksem hulk komponente, mis vastutavad esialgsete muutujate varieeruvuse  eest.   
Faktoranalüüs ja peakomponentide analüüs on matemaatilises mõttes erinevad. Faktoranalüüsi käigus eeldatakse, et mõõdetud muutujate varieeruvuse eest vastutavad tekkivad ühisfaktorid ja unikaalsed faktorid. Peakomponentide analüüsi käigus tekitatakse uued muutujad lihtsalt kui lineaarkombinatsioonid mõõdetud muutujatest (vaadake loengu konspektist jooniseid).
Faktoranalüüsi on mõistlik kasutada, kui uurija on huvitatud faktoritest, mis vastutavad teatud hulga mõõdetud muutujate varieeruvuse eest. Peakomponentide analüüsi tuleks kasutada, kui uurija soovib lihtsalt andmeid taandada.



# Faktoranalüüs
Faktoranalüüsi eesmärk on kirjeldada mingit suuremat hulka tunnuseid väiksema arvu hüpoteetiliste tunnuste ehk faktorite kaudu.
Faktoranalüüsi eeldused:  

* Arvtunnused (võivad olla järjestusskaalal)  
* Tunnuste vahel peaks leiduma märkimisväärseid seoseid, seosed peaksid olema lineaarsed  
* Vaatlusi/mõõtmisi vähemalt 10 korda rohkem kui mõõdetud tunnuseid  

Faktoranalüüsi tegemiseks on R-is vähemalt paar erinevat võimalust. Antud praktikumis kasutame kahte lisamoodulit: *psych* ja *GPArotation* (see on vajalik faktormudeli pööramiseks).

```{r, eval = F}
install.packages("psych") 
install.packages("GPArotation")
```

Kui lisamoodulid on edukalt instelleeritud, siis tuleb need ka aktiveerida:  
```{r, warning=F, message=F}
library(psych)
library(GPArotation)
```

Vaatame alustuseks suheliselt lihtsat faktormudelit, mille puhul teame, et sellel on 2-faktoriline struktuur. Laadige R’i andmestik nimega bfi.

## Eelduse kontroll - nõrgad ja tugevad seosed tunnuste vahel
Faktoranalüüsi alguspunktiks on analüüsi kaasatavate muuutjate vaheliste korrelatsioonide maatriks. Mõistliku faktorlahendi eelduseks on paraja tugevusega korrelatsioonide kogumid maatriksis. See tähendab, et muutujad, mis seostuvad teistega liiga nõrgalt või liiga tugevalt, võivad osutuda probleemseks. 

Teeme alguses tavalise korrelatsioonimaatriksi vastavate tunnustega. Hetkel kasutame andmestikust esimest kümmet veergu. Saame teha uue andmestiku, kus on ainult need veerud:
```{r}
bfi2 <- bfi[,1:10]
```
Korrelatsioonimaatriksi saab funktsiooni *cor* abil (mille argument *use=“complete”* jätab arvutustest välja puuduvate väärtustega andmeread). Funktsioon *round* selle ümber aitab ümmardada korrelatsioonikordajad kahe komakohani. 
```{r}
bfi2matrix <- round(cor(bfi2, use="complete"), 2)
bfi2matrix
```

Üldiselt hinnatakse siin nõrgaks korrelatsiooniks korrelatsioone alla 0.3 ja tugevaks loetaks korrelatsioone üle 0.8. Tunnused, mis ei ole teistega seotud või on liiga tugevalt teistega seotud, peaks analüüsist välja jätma. Kui vaatame meie korrelatsioonimaatriksti, siis näeme, et sellise otsuse tegemine ei ole sugugi lihtne. Korrelatsioonimaatriksi põhjal otsustamine ongi üsna subjektiivne. Subjektiivsuse vältimiseks kasutatakse üldisemaid teste, mis näitavad, kas andmestikus on üldiselt porbleeme madalate või tugevate seostega.   

**Bartletti test** näitab, kas maatriksis (seda funktsiooni saab kasutada korrelatsioonimaatriksi ja toorandmete peal) on liiga palju nõrku korrelatsioone. (Täpsemalt öeldes võrdleb see korrelatsioonimaatriksit sellise maatriksiga, millel on väljaspool peadiagonaali nullid.) Bartletti testi saab kasutada *psych* paketi funktsiooni *cortest.bartlett* abil:
```{r}
cortest.bartlett(bfi2)#argumendiks saab anda andmestiku tunnustega või vastavate tunnuste põhjal koostatud korrelatsioonimaatriksi
```
Praegusel juhul on p-väärtus alla 0.05. P-väärtus üle 0.05 näitab probleeme nõrkade korrelatsiooniseoste rohkusega. Sellisel juhul tuleks vaadata korrelatsioonimaatriksit ennast ning katsuda üles leida muutujad, mille puhul esineb vaid üksikuid korrelatsioone väärtusega üle 0.3-e. Nende muutujate puhul tuleks kaaluda faktoranalüüsist välja jätmist. 

**Korrelatsioonimaatriksi determinandi** abil saame uurida vastupidise probleemi ehk liiga tugevate korrelatsioonide esinemist.
```{r}
det(bfi2matrix)
```
Probleeme multikollineaarsusega (ehk liiga tugevate muuutjate vaheliste seostega) näitab determinandi väärtus alla $0.00001−e0.00001−e$ (ehk $10− 10^−5$). Kui probleemne multikollineaarsus siiski kinnitust leiab, tuleks korrelatsioonimaatriksist üles otsida kordajad üle 0.9 ja üks vastavatest muutujatest välja jätta. Vahel võib probleeme valmistada ka olukord, kus 3 muutujat korreleeruvad kõik omavahel 0.6 kanti.

## Faktormudeli koostamine
Faktoranalüüsi siseselt on olemas erinevaid faktorite leidmise meetode. Üheks peamiseks valikukriteeriumiks võiks olla, kas me soovime üldistada leitavat faktorstruktuuri suuremale populatsioonile (eeldusel, et meie valim koosneb populatsioonist juhuslikult valitud inimestest) või piirduda ainult selle valimiga, mille peal arvutusi tegema hakkame. Populatsioonile üldistamist võimaldavatest on tuntuim **suurima tõepära (maximum likelihood) meetod**. Kui üldistamise vajadust pole, võib kasutada **peatelgede meetodi (principal axis)**. Peatelgede meetodi soovitatakse eelistada ka siis, kui analüüsi kaasatavates andmetes esineb normaaljaotusest kõrvalekalduvaid muutujaid.

Teeme *psych* mooduli funktsiooni *fa* abil 2-faktorilise mudeli kasutades faktorite leidmiseks suurima tõepära meetodi ja faktorite pööramiseks oblimin-meetodit. Salvestame mudeli nimega fa.mudel1.

```{r}
fa.mudel1 <- fa(bfi2, nfactors = 2, rotate="oblimin", fm="ml")
```
Vaatame natuke lähemalt funktsiooni *fa* argumente:  
**Andmestiku nimi** - esimesel kohal on alati andmestiku nimi.   
**nfactors** - faktorite arv. Antud juhul eeldame, et andmestikus on kaks latentset faktorit. Tehke analüüs läbi ka suurema arvuga. Kuidas tulemused erinevad esialgsest analüüsist?       
**fm** - faktorite leidmise meetod. *fm = ml* - kasutame suurima tõepära meetod (mõistlik kui soovida üldistada faktorstruktuuri antud valimilt tervele populatsioonile); *fm=pa* - peatelgede meetod (järeldused piiratud antud valimiga).  
**rotate** - kas pöörata faktorlahendit ja millise meetodiga. *rotate = none* - jätab pööramata; *rotate=varimax* - pöörab faktoreid ortogonaalselt; *rotate= oblimin* - pöörab faktoreid kaldnurkselt (see on vaikimisi väärtus).  
Pööramise eesmärgiks on saavutada võimalikult lihtne faktorstruktuur, kus iga muutuja laaduks tugevalt ainult ühele faktorile ja teistele nõrgalt. Matemaatiliselt pööramine faktorlahendi põhiolemust ei muuda: summaarne seletusprotsent ja tunnuste kommunaliteedid jäävad samaks. Kuid faktorlahend muutub lihtsamini tõlgendatavaks ja omaväärtused jaotuvad faktorite vahel ühtlasemalt. Teeme faktormudeli, kus kasutame direct oblimin meetodit.  
Eristatakse kahte tüüpi pööramist: **ortogonaalset ehk täisnurkset** ja **mitteortogonaalset ehk kaldnurkset**. Enne pööramist on faktorid sõltumatud, nad ei ole omavahel korreleeritud. Ortogonaalne pööramine jätabki olukorra selliseks; faktorite vahelised korrelatsioonid ei ole lubatud ja kõiki faktoreid pööratakse ühepalju. Kaldnurkse pööramise puhul on faktorite-vahelised korrelatsioonid lubatud ja iga faktorit võib pöörata erineval määral. Otsus kumba pööramist eelistada, peaks tuginema eelkõige teoreetilistele kaalutlustele.  
Kui me eeldame, et faktorid peaksid olema üksteisest sõltumatud, tuleks eelistada ortogonaalset pööramist (*varimax*). Kui aga teooria ütleb, et faktorid on omavahel korreleeritud, on mõistlik valida kaldnurkne pööramine (*oblimin*).     

## Faktormudeli väljund
Faktormudeli fa.mudel1 väljundi saame kätte sellesama nime abil. Samas on ehk natuke kavalam kasutada funktsiooni print.psych, millele saame argumendi *cut* abil anda piirväärtuse, millest väiksemad faktorlaadungid ära peidetakse. Mitteoluliste laadungite peitmine teeb faktormudeli tõlgendamise reeglina lihtsamaks. Peidame ära 0.3-st väiksemad laadungid. Samuti saame argumendi *sort=TRUE* abil reastada laadungid faktorite siseselt suuruse järgi.

```{r}
print.psych(fa.mudel1, cut=0.3, sort=TRUE)
```

Väljundis on esimesena näha **faktorlaadungite tabel** (Standardized loadings…). **Laadung** näitab väite ja faktori vahelise korrelatsioonikordaja väärtust (kaldnurkse pööramise korral regressioonikordaja). Iga väite/muutuja puhul tuleks vaadata, millisele faktorile see tugevalt laadub. Rusikareegilina võib oluliseks pidada laadungit absoluutväärtusega $0.3 − 0.4$ (sõltuvalt valimi suurusest). Seejärel tuleks faktoreid tõlgendada. Faktorite tähendus moodustub neile tugevalt laaduvatest muutujatest. Mis on ühele faktorile tugevalt laaduvate muutujate ühisosa? Antud juhul näeme, et sotsiaalsusega seotud väidete (tunnused A1-A5) suuremad laadungid ongi koondunud ühte faktorisse ja meelekindluse väited (C1-C5) teise faktorisse. Mida suurem laadungi absoluutväärtus, seda olulisem on muutuja faktori tõlgendamisel. Arvesse tuleks võtta ka faktorlaadungi märki. Nt väide A1 seostub faktoriga negatiivselt (tabelist bfi.dictionary võib näha, et väite sisu on *Am indifferent to the feelings of others*), samas kui nt A2 (*Inquire about others’ well-being*) seostub faktoriga positiivselt. Sarnane on lugu ka meelekindluse väidete puhul. Väited C4 (*Do things in a half-way manner*) ja C5 (*Waste my time*) seostuvad faktoriga negatiivselt, samas kui ülejäänud väited positiivselt.
  
Lisaks laadungitele on tabeli paremas servas veel paar tulpa. **Tulbas nimega h2** paiknevad **kommunaliteedid**, mis näitavad kui suure osa muutuja variatiivususest faktorid summaarselt ära kirjeldavad. Kui mõne väite kommunaliteet on teistest oluliselt väiksem, tasub kaaluda selle analüüsist välja jätmist, kuna pole teistega lineaarselt seotud. **Tulbas u2** olevad arvud näitavad iga muutuja unikaalse variatiivsuse hulka (st nad on see osa tunnuse varitiivsusest, mis kommunaliteedist üle jääb). Funktsiooni *fa* väljundis on laadungite tabelil veel üks **tulp com** (ehk *complexity*, keerukus). See näitaja iseloomustab faktorite arvu, mida antud faktorlahendis muutuja kirjeldamiseks vaja läheb. Allpool on ära toodud ka keskmine keerukus, mida saab kasutada erinevate faktormudelite võrdlemiseks. Kuna me tahame, et faktorstruktuur oleks võimalikult lihtne (st iga muutuja seostuks ainult ühe faktoriga), siis mida lähemal on keskmine keerukus 1-le, seda parem faktormudel.

Faktorlaadungite tabeli all näeme **faktorite omaväärtusi** (*SS loadings ehk sum of squared loadings*). Samuti näeme, kui suure osa andmete hajuvusest iga faktor seletab (*Proportion Var*) ja kui suure osa faktorite poolt seletatavast hajuvusest mingi faktor seletab(*Proportion Explained*). Lisaks on kaks viimast näitajat ära toodud ka kumulatiivselt. Kui tahame teada, kui suure osa andmete hajuvusest antud mudeli faktorid ära kirjeldavad, tuleks vaadata rea *Cumulative var* kõige parempoolsemat väärtust.

Omaväärtuste ja seletusprotsentide tabelist allapoole on ära toodud veel **mudeli sobitusastme näitajad**. Näitaja *Fit based upon off diagonal values* põhineb mudeli jääkide ja tegelike korrelatsioonide suhtelise suuruse võrlemisel. Jäägid kujutavad endast mudeli järgi taastatud korrelatsioonimaatriksi ja tegeliku korrelatsioonimaatriksi vahelisi erinevusi. Antud näitaja on saadud jagades jääkide ruutsumma tegelike korrelatsioonide ruutsummaga ja lahutades saadud arvu 1-st. Väärtused üle 0.95-e näitavad mudeli head sobitusastet.

## Faktorite arvu määramine
Faktoranalüüsi väljundist saame kätte faktorite omaväärtused.
**Kaiseri kriteerium** - kõigi faktorlahendisse võetavate faktorite omaväärtused peavad olema vähemalt 1, R rakendab seda kriteeriumit automaatselt. R'i väljundis ongi ainult näidatud sellele kirteeriumile vastavate faktorite omaväärtused. Saame vaadata ka kõikide faktorite omaväärtusi:
```{r}
fa.mudel1$values
```

**Catelli kriteerium** - omaväärtuste joonise põhjal otsustamine. Alles tuleks jätta faktorid, mis jäävad omaväärtuste graafikul nn jõnksupunktist ülespoole. Kriteeriumi hindamiseks vajaliku faktormudeli omaväärtuste graafiku saame teha andes omaväärtused ette funktsioonile plot. Funktsiooni argument type = b (b nagu both) ütleb, et tahame joonisele nii omaväärtusi tähistavaid punkte, kui ka neid ühendavaid jooni.

```{r}
plot(fa.mudel1$values, type="b")
```
  
## Faktorskoorid   
Kui me ülalpool tegime mudeli nimega *fa.mudel1*, tellisime funktsioonilt *fa* ka faktorskooride arvutamise. Need skoorid näitavad, kus iga vastaja teatud faktoril paikneb. Skooride arvutamiseks kasutatakse inimeste vastuseid väidetele ja faktorlaadungeid. Lihtsustades võib öelda, et inimese faktorskoor saadakse korrutades iga väite vastuse selle väite laadungiga ning need korrutised liidetakse kokku. (Tegelikkuses on arvutused natuke keerulisemad. Kõigepealt arvutatakse välja faktorskoori koefitsiendid, mis saadakse laadungite maatriski korrutamisel algse korrelatsioonimaatriksi pöördmaatriksiga ning neid koefitsiente hakatakse siis korrutama ja kokku liitma.)


Faktorskoore saab kasutada edasistes arvutustes, nt võime uurida, kas faktor seostub mingite teiste muutujatega. Skoorid saame mudelist kätte lisades mudeli nime lõppu dollari märgi ja "*scores*". Salvestame skoorid eraldi tabelisse ja vaatame esimesi ridu.
```{r}
skoorid <- data.frame(fa.mudel1$scores)
head(skoorid)
```

R on pannud faktoritele mittemidagiütlevad nimed "ML2" ja "ML1". Eelnevalt nägime faktorlaadungite tabelist, et esimesele faktorile laadusid tugevamalt meelekindluse väited ja teisele sotsiaalsuse väited. Nimetame selguse huvides faktorid ümber: paneme meelekindluse faktorile nimeks C (nagu *Conscientiousness*) ja sotsiaalsuse faktorile A (nagu *Agreeableness*).
```{r}
colnames(skoorid) <- c("C", "A")
```


# Cronbachi alfa
Faktoranalüüsi kasutatakse eriti sageli küsimustikuandmete analüüsimiseks. Kui oleme kindlaks teinud, millised väited mingile faktorile laaduvad, tahame vahel arvutada küsimustiku alaskaalade kohta ka reliaablusnäitajaid nagu Cronbachi alfa. Selle jaoks on *psych* moodulis olemas funktsioon *alpha*, millele tuleks ette anda alaskaala väidete toorandmed. Antud juhul teame, et sotsiaalsuse väited paiknevad tabeli bfi2 tulpades 1-5. Seega saaksime sotsiaalsuse alaskaala alfa kätte nii:

```{r}
alpha(bfi2[,1:5])
```

Üldjuhul saab programm ise aru, kui alaskaala mõnede väidete vastused seostuvad teistega negatiivselt ja võtab seda arvesse. Aga kindluse mõttes võime funktsioonile alpha argumendi keys abil ette anda ka väidete suuna. Tagurpidi väiteid tähistab -1 ja õiges suunas väiteid 1.

```{r}
alpha(bfi2[,1:5], keys=c(-1, 1, 1, 1, 1))
```

Väljundi ülaosas olev *raw alpha* ongi sotsiaalsuse alaskaala Cronbachi alfa. Tabelis *Reliability if an item is dropped* on näha, mis juhtuks skaala alfaga, kui väide välja jätta. Kui selles on näha väiteid, mille alfa väärtus on suurem kui terve skaala oma, siis nende välja jätmine parandaks skaala üldist reliaablust.


# Peakomponentide analüüs
Peakomponentide analüüsi eesmärk on välja selgitada väiksem hulk komponente, mis vastutavad esialgsete muutujate varieeruvuse eest. Faktoranalüüs ja peakomponentide analüüs on matemaatilises mõttes erinevad. Faktoranalüüsi käigus eeldatakse, et mõõdetud muutujate varieeruvuse eest vastutavad tekkivad ühisfaktorid ja unikaalsed faktorid. Peakomponentide analüüsi käigus tekitatakse uued muutujad lihtsalt kui lineaarkombinatsioonid mõõdetud muutujatest.
Faktoranalüüsi on mõistlik kasutada, kui uurija on huvitatud faktoritest, mis vastutavad teatud hulga mõõdetud muutujate varieeruvuse eest. Peakomponentide analüüsi tuleks kasutada, kui uurija soovib lihtsalt andmeid taandada.

Peakomponentide analüüsi saab teha funktsiooni principal abil. Selle argumendid on samad mis funktsioonil fa (välja arvatud puuduv faktorite leidmise meetodi argument fm). Ülaltoodud faktoranalüüsi mudelile analoogse peakomponentide mudeli saaksime teha nii:

```{r}
pc.mudel1 <- principal(bfi2, nfactors=2, rotate="varimax")
```
```{r, eval = F}
pc.mudel1 #tulemuste vaatamine
```
Tehke see analüüs enda arvutis läbi ja võrrelega tulemusi eelneva analüüsiga. Kas leiate tulemustes erinevusi?  

# Ülesanded     
Kastuage andmestikku **WV6_EST2011**.
   
Ülesanne 1. Kirjeldav statistika. Lahendage järgnevad ülesanded:     
1.1. valimi suurus:   
1.2. milline on sooline jaotus:  
1.3. vastajate keskmine vanus:  
1.4. kõige noorem vastaja:  
1.5. kõige vanem vastaja:  
1.6. naiste vanuse keskmine ja standardhälve:  
1.7. meeste keskmine vanus ja standardhälve:  
   
Ülesanne 2. Regressioon. Kas eluga rahulolu (muutuja "*SatisfactionWithLife*") ennustab vanust?    
2.1 Kas mudel on statistiliselt oluline?  
2.2 Mis on selle väite olulisuse tõenäosus?    
2.3 Kui suure osa sõltuva muutuja variatiivsusest kirjeldab ära mudel?  
2.4 Missugune on mudeli standardiseerimata võrrand?    
   
Ülesanne 3. Mitmene regressioon. Kas vanust ennustavad terviseseisund (muutuja "*StateOfHealth*"), õnnelikkus (muutuja "*FeelingOfHappiness*") ning finantsseisuga rahulolu (muutuja "*Sat_w_financial*")?    
3.1 Kas mudel on statistiliselt oluline?  
3.2. Kui suure osa seletas ära mudel sõltuva muutuja variatiivsusest?   
3.3. Kas kõik prediktorid olid olulised?   
3.4. Milline prediktor ennustas kõige paremini vanust?    
    
Kasutage andmestikku nimega **bfi**.  
  
Ülesanne 4. Tehke läbi faktoranalüüs ka teiste tunnustega. Kasutage korraga kõiki alaskaalasid ja vaadake, kas saate 5-faktorilise mudeli. 


