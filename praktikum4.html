<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Martin Kolnes, Karin Täht" />


<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Kodu</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Praktikumide materjalid
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="praktikum1.html">1. Praktikum - sissejuhatus</a>
    </li>
    <li>
      <a href="praktikum2.html">2. Praktikum - joonised</a>
    </li>
    <li>
      <a href="praktikum4.html">4. Praktikum - regressioon</a>
    </li>
    <li>
      <a href="praktikum5.html">5. Praktikum - logistiline regressioon</a>
    </li>
    <li>
      <a href="praktikum6.html">6. Praktikum - eksploratiivne faktoranaluus</a>
    </li>
    <li>
      <a href="praktikum7.html">7. Praktikum - Struktuurvorrandite mudelid</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lisamaterjalid
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lisa_andmente_importimine.html">Andmete importimine</a>
    </li>
    <li>
      <a href="praktikum1_korrelatsioon.html">Korrelatsioon</a>
    </li>
    <li>
      <a href="praktikum1_subsetting.html">Andmete eraldamine</a>
    </li>
    <li>
      <a href="praktikum2_ttestid.html">Keskmiste vordlemine</a>
    </li>
  </ul>
</li>
<li>
  <a href="lugemist.html">Soovitused</a>
</li>
<li>
  <a href="about.html">Kontakt</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore"><ol start="4" style="list-style-type: decimal">
<li>praktikum: Lineaarne regressioon</li>
</ol></h1>
<h4 class="author"><em>Martin Kolnes, Karin Täht</em></h4>

</div>


<div id="praktikumi-eesmargid" class="section level1">
<h1>Praktikumi eesmärgid</h1>
<ul>
<li>Eelnevate teemade kordamine: andmete lugemine R’i; jooniste tegemine paketiga ggplot2; korrelatsioonanalüüs<br />
</li>
<li>Paarisregressioon: funktsioon lm(ennustatav~ prediktor)<br />
</li>
<li>Mitmene regressioon: funktsioon lm(ennustatav muutuja ~ esimene prediktor + teine prediktor …)<br />
</li>
<li>Mudelite võrdlemine funktsiooniga <em>anova()</em><br />
</li>
<li>Jääkide analüüs<br />
</li>
<li>Regresioonanalüüsi eelduste kontrollimine</li>
</ul>
</div>
<div id="kordamine" class="section level1">
<h1>Kordamine</h1>
<p>Laadige alla praktikumi koodi ja andmeid sisaldav fail <em>pisa.csv</em>.</p>
<ol style="list-style-type: decimal">
<li>Lugega andmestik <em>pisa</em> R’i</li>
</ol>
<pre class="r"><code>valige_andmestiku_nimi &lt;- read.csv(&quot;sisseloetav andmestik&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>Vaadake kirjeldavaid statistikuid matemaatik (PV1MATH), lugemise (PV1READ) ja loodusteaduste (PV1SCIE) alatestide tulemuste kohta.</p></li>
<li><p>Tehke eraldi histogrammid soo alusel loodusteaduste testi tulemuste kohta.</p></li>
<li><p>Missugused on korrelatsioonid nende kolme testi (PV1MATH, PV1READ, PV1SCIE) vahel? Võrrelge korrelatsioone erinevate klasside tulemuste vahel.</p></li>
</ol>
<pre class="r"><code>library(&quot;psych&quot;)
corr.test()#argumendiks saate panna mitu veergu</code></pre>
</div>
<div id="regressioonanaluus" class="section level1">
<h1>Regressioonanalüüs</h1>
<p>Regressioonanalüüs on üks kõige sagedamini kasutatavaid statistilisi meetode. Selle eesmärgiks on tuletada valem, mis seostab omavahel sõltuva muutuja ja ühe või mitu sõltumatut muutujat ehk prediktorit. Tuletatud valemit võib kasutada sõltuva muutuja väärtuste ennustamiseks prediktorite väärtuste põhjal. Aga enamasti kasutatakse seda määramaks kindlaks, kas ja millised sõltumatud muutujad omavad olulist seost sõltumatu muutujaga. Oletame, et oleme inimeste kohta mõõtnud kahte näitajat, nimetagem neid X ja Y. Me tahame ennustada Y väärtusi (sõltuv muutuja) X-i väärtuste kaudu (sõltumatu muutuja). Sellisel juhul saame nendevahelise regressioonseose valemi kirjutada nii: <span class="math display">\[Y = b_{0} + b_{1}X + e\]</span><br />
Y ja X tähistavad selles vastavalt inimeste sõltuva ja sõltumatu tunnuse väärtusi. <span class="math inline">\(b_0\)</span> on vabaliige, mis ütleb, milline on sõltuva muutuja Y väärtus, kui sõltumatu muutuja X väärtus on 0. <span class="math inline">\(b_1\)</span> on regressioonikordaja, mis ütleb, kui palju muutub sõltuv muutuja Y juhul kui sõltumatu muutuja X väärtus muutub ühe ühiku võrra. <span class="math inline">\(b_0\)</span> ja <span class="math inline">\(b_1\)</span> nimetame mudeli parameetriteks, need on inimeste jaoks ühised. <span class="math inline">\(e\)</span> on mudeli viga (nimetatakse ka jääkideks või hälveteks). Mudel ei suuda reeglina andmeid seletada täielikult ja <span class="math inline">\(e\)</span> ongi mudeli ja tegelike andmete vaheline erinevus mingi konkreetse inimese puhul. Regressioonianalüüsi puhul anname statistikaprogrammile ette inimeste X ja Y väärtuse ning saame tagasi b-de väärtuse ja iga inimese kohta ka <span class="math inline">\(e\)</span> väärtuse. Kui oleme mõõtnud kolme muutujat (nimetagem neid Y , X1 ja X2) ja tahame teada kas X1 ja X2 mõlemad mõjutavad Y -it, omandaks valem sellise kuju: <span class="math display">\[Y = b_{0} + b_{1}X_{1} + b_{2}X_{2} + e\]</span></p>
<p>Ehk siis üks bX korrutis on valemisse juurde tulnud ja sellest tulenevalt on vaja kindlaks määrata väärtus ühe täiendava <span class="math inline">\(b\)</span> jaoks. üldistatult võibki öelda, et iga täiendav sõltumatu muutuja lisab valemisse veel ühe <span class="math inline">\(bX\)</span> korrutise ja kindlaks määramist vajab üks täiendav parameeter.</p>
</div>
<div id="paarisregressioon" class="section level1">
<h1>Paarisregressioon</h1>
<p>Teeme alustuseks lihtsa regressioonanalüüsi mudeli, milles on sõltuv tunnus ja ainult üks sõltumatu tunnus ehk prediktor. Võtame sõltuvaks tunnuseks PISA uuringu loodusteaduste alatesti skoori (tabeli pisatulp nimega PVSCIE) ja ennustame seda teaduse tähtsaks pidamise kaudu(tunnus nimega GENSCIE). Mudeli koostamiseks kasutame R-i funktsiooni <em>lm (linear model)</em>, millele anname mudelisse minevad muutujad valemi kujul <strong>sõltuv tunnus <span class="math inline">\(\sim\)</span> sõltumatu tunnus</strong> ja argumendi <em>data</em> abil andmetabeli nime, millest muutujad võetakse.</p>
<pre class="r"><code>pisa.mudel1 &lt;- lm(PVSCIE ~ GENSCIE, data=pisa)</code></pre>
<p>Salvestasime mudeli nimega <em>pisa.mudel1</em>. Selle nime abil saame hiljem kätte meid huvitavad mudeli parameetrid ja ka mudeli jäägid. Kui mudelisse kaasatud muutujates esineb puuduvaid andmeid, tuleb nende välja jätmiseks lisada funktsioonile lm veel täiendav argument na.action=na.omit. Sama mudeli võib põhimõtteliselt kirjutada ka ilma <em>data</em> argumendita sellisel kujul:</p>
<pre class="r"><code>pisa.mudel1 &lt;- lm(pisa$PVSCIE ~ pisa$GENSCIE)</code></pre>
<p>Hetkel on meil mudelis ainult 2 muutujat ja pole suurt vahet, kumba tähistust eelistada, aga suurema muutujate arvuga mudeliste puhul on data argumendiga tähistus lühem ja üldiselt mugavam. Nüüd kui oleme mudeli defineerinud, vaatame mudeli väljundit, mille saame kätte funktsiooni <em>summary</em> abil:</p>
<pre class="r"><code>summary(pisa.mudel1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = pisa$PVSCIE ~ pisa$GENSCIE)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -294.763  -51.218    1.355   52.027  244.439 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   530.272      1.098   482.8   &lt;2e-16 ***
## pisa$GENSCIE   31.376      1.230    25.5   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 74.73 on 4766 degrees of freedom
## Multiple R-squared:  0.1201, Adjusted R-squared:  0.1199 
## F-statistic: 650.2 on 1 and 4766 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Mida mudeli väljundi osad tähendavad? Kuna seda tüüpi väljund on antud praktikumis üks kõige olulisemaid, siis vaatame selle üksikasjalikumalt läbi. Hakkame väljundi ülaosast pihta ja liigume järjest allapoole. Tuleb rõhutada, et tegemist pole väljundi osade tähtsuse järjekorraga.</p>
<p>Esimene osa <strong>Call</strong> lihtsalt kordab üle, millised muutujad on mudelisse kaasatud.</p>
<p><strong>Residuals</strong> toob ära mõned näitajad mudeli jääkide kohta. Mudeli jäägid kujutavad endast erinevust andmete ja mudeli vahel. Tegemist on selle osaga andmetest, mida mudel ära seletada ei suuda. Teatavasti peaksid regressioonimudeli jäägid olema normaaljaotusega ja mediaan peaks olema 0-i ligiduses. See tähendab, et 1. kvartiil (1Q) ja 3. kvartiil (3Q) peaksid olema vastasmärgilised aga absoluutväärtuselt sarnased. Samamoodi ka Min ja Max, kuigi nende puhul on suuremad erinevused üsna tavalised. Kui erinevused on väga suured, võib tekkida probleeme mudeli üldistamisel teistele valimitele. Jääke vaatame hiljem lähemalt, see rida siin võimaldab ainult kiirpilku.</p>
<p>Tabelis <strong>Coefficients</strong> on kirjas mudeli parameetrid koos nende statistilise usaldusväärsuse näitajatega. Esimesel real (Intercept) tulbas <strong>Estimate</strong> on toodud mudeli vabaliikme väärtus (antud juhul 530.272). Seda võib tõlgendada nii, et kui sõltumatu muutuja väärtuseks on 0, siis mudel ennustab loodusteaduste alatesti skooriks just selle numbri. Teisel real tulbas <strong>Estimate</strong> on toodud sõltumatu tunnuse GENSCIE (mis tähistas teaduse oluliseks pidamist) regressioonikordaja, mille väärtuseks on 31.376. See tähendab, et kui sõltumatu tunnus muutub ühe ühiku võrra, muutub sõltuv tunnus 31.376 ühiku võrra. Antud juhul on kordaja positiivne, mis tähendab, et kui sõltumatu muutuja suureneb, kasvab ka sõltuv muutuja. Negatiivne kordaja tähendab, et sõltumatu muutuja suurenedes sõltuv muutuja hoopis väheneb. Kui prediktor omab olulist seost sõltuva muutujaga, peaks kordaja olema nullist erinev. Tulbas <strong>Std. Error</strong> on toodud regressioonikordaja standardviga. Standardviga näitab, kui erinevad oleksid antud regressioonikordaja väärtused erinevates valimites. Väike standardviga tähendab, et ka teistes valimites võib oodata antud valimi omale sarnast kordajat. Tulbas <strong>t-value</strong> on toodud t-väärtus mis kujutab, endast regresioonikordaja ja standardvea suhet. Olulist seost omavate prediktorite puhul peaks regressioonikordaja olema standardveaga võrreldes võimalikult suur. Laias laastus võib õelda, et vähemalt 2 korda suurem ehk siis t &gt; 2. (Sellest järeldub ka, et väikese standardvea korral võib ka väike reg.kordaja olla oluline). Tulbas <strong>Pr(&gt;|t|)</strong> on toodud p-väärtus, mis kontrollib hüpoteesi, et t väärtus pole 0-st oluliselt erinev. Antud juhul tähistab *** lõpus, et p &lt; 0.001, mis viitab, et tõenäosus, et t pole 0-st erinev on alla 0.1% ehk väga väike ja sellest tulenevalt võib õelda, et sõltumatu tunnus GENSCIE (ehk teaduse oluliseks pidamine) omab statistiliselt usaldusväärset seost loodusteaduste alatesti skooriga.</p>
<p>Tabeli järel on selgitus selle kohta, milline tärnide arv tabeliridade lõpus, tähistab millist statistilise olulisuse nivood. Seejärel on toodud näitaja <strong>Residual standard error</strong>, mis kujutab endast põhimõtteliselt mudeli jääkide standardhälvet, aga üldiselt see meid väga ei huvita.</p>
<p><strong>Multiple R-squared</strong> on mudeli determinatsioonikordaja (<span class="math inline">\(R^2\)</span>), mis näitab, kui suure osa sõltuva tunnuse hajuvusest mudel (mis antud juhul koosneb ainult tunnusest GENSCIE) ära seletab. Praegusel juhul on selle väärtuseks 0.1201, korrutades selle 100-ga saame näitaja protsentides ehk siis 12% alatesti skooride hajuvusest saab seletada tunnuse GENSCIE abil (ja 88% hajuvusest tingitud mingitest muudest asjaoludest). <strong>Adjusted R-squared</strong> näitab, kui suurt <span class="math inline">\(R^2\)</span>-e võime oodata kui hinnata seost antud valimi asemel terves populatsioonis. See näitaja on alati väiksem, kui Multiple R-squared, aga praegusel juhul (0.1199) on erinevus väga väike, mis on suures osas tingitud ka sellest, et meie valim on väga suur.</p>
<p>Viimasel real on ära toodud <strong>F-suhe</strong> koos oma vabadusastmete ja p-väärtusega. Näitaja kujutab, endast mudeli poolt seletatava hajuvuse ja jääkhajuvuse suhet. Mida suurem on F-suhe seda parem, rea lõpus toodud p-väärtus aitab hinnata F-suhte suurust ja seeläbi mudeli kvaliteeti. Antud juhul on F-suhte p-väärtus &lt; 2.2e-16, see tähendab väiksem kui <span class="math inline">\(2.2 * 10^-16\)</span> ehk siis tõenäosus, et nii suur F-suhe on saadud ainult tänu juhusele on väga väike.</p>
<p><span class="math inline">\(R^2\)</span> ja F-suhe on saadud võrreldes mudelit sellise mudeliga, milles muutujate-vaheline seos puudub (ainult vabaliikmega mudel, vabaliikme väärtuseks võetakse sõltuva muutuja keskmine). Võime järeldada, et meie mudel on parem kui mudel, milles muutujate vaheline seos puudub.</p>
<p>Mudeli väljundist teada saadud parameetrite abil võime loodusteaduste alatesti ja teaduse oluliseks pidamise seost väljendada järgevalt:</p>
<p><span class="math display">\[loodusteaduste alatesti skoor = 530.272 + 31.376 * teaduse oluliseks pidamine\]</span></p>
<div id="ulesanded---paarisregressioon" class="section level2">
<h2>Ülesanded - paarisregressioon</h2>
<ol style="list-style-type: decimal">
<li>Tehke paarisregressiooni mudel, mis ennustab matemaatika alatesti skoori (tunnus PVMATH) teaduse tähtsaks pidamise kaudu (GENSCIE). Kas seos on oluline? Kui suure osa matemaatika testi skooride hajuvusest mudel ära seletab? Mitme punkti võrra muutub matemaatika skoor kui sõltumatu muutuja muutub ühe punkti võrra?</li>
</ol>
</div>
</div>
<div id="mitmene-regressioon" class="section level1">
<h1>Mitmene regressioon</h1>
<p>Teeme uue regressioonimudeli, milles jääb sõltumatu muutujana alles loodusteaduste alatesti skoor (PVSCIE) ja prediktorina teaduse oluliseks pidamine (GENSCIE). Lisame veel kaks uut prediktorit: huvi teaduse vastu (INTSCIE) ja motivatsioon loodusteaduste õppimiseks (INSTSCIE).</p>
<pre class="r"><code>pisa.mudel2 &lt;- lm(PVSCIE ~ GENSCIE + INTSCIE + INSTSCIE, data=pisa)</code></pre>
<p>Nagu näha on mudeli valemi paremal poolel olevad sõltumatud muutujad omavahel eraldatud + märgiga. Vaatame mudeli väljundit, mille saime funktsiooni <em>summary</em> abil.</p>
<pre class="r"><code>summary(pisa.mudel2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = PVSCIE ~ GENSCIE + INTSCIE + INSTSCIE, data = pisa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -295.759  -50.715    1.342   51.460  246.590 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  528.869      1.118 472.865  &lt; 2e-16 ***
## GENSCIE       30.666      1.300  23.598  &lt; 2e-16 ***
## INTSCIE       10.600      1.631   6.498 8.95e-11 ***
## INSTSCIE      -9.236      1.523  -6.062 1.44e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 74.29 on 4764 degrees of freedom
## Multiple R-squared:  0.1307, Adjusted R-squared:  0.1301 
## F-statistic: 238.7 on 3 and 4764 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Vaatame mudeli üldist sobitusastet näitavat determinatsioonikordajat <span class="math inline">\(R^2\)</span> (Multiple R-squared) väljundi alaosas. Selle väärtuseks on 0.1307. Korrutades selle 100-ga saame, et mudel seletab ära umbes 13.1% sõltuva muutja hajuvusest. Mäletatavasti oli see näitaja esimese mudeli puhul 12%. Seega on kasv väga väike, umbes 1%. Adjusted R-square on jätkuvalt väga sarnane Multiple R-square’le.</p>
<p>Järgmisena uurime tabelis <strong>Coefficients</strong> tulbas <strong>Estimates</strong> olevaid mudeli parameetrite väärtusi. Vabaliikme väärtus on 528.869. See tähendab, et kui kõigi kolme prediktori väärtus juhtub olema 0, võime oodata sellist loodusteaduste testi skoori. Kõik kolm prediktorit omavad olulist seost sõltuva muutujaga. Tunnuse GENSCIE (teaduse oluliseks pidamine) regresioonikordaja on 30.666. Mitmese regressiooni korral näitavad regressioonikordajad, millisel määral iga prediktor mõjutab sõltuvat muutujat eeldusel, et teised prediktorid samal ajal ei muutu. See tähendab, et kui GENSCIE suureneb ühe ühiku võrra, võime oodata, et testiskoor suureneb 30.666 ühiku võrra. Seda eeldusel, et kahe ülejäänud prediktori väärtused jäävad samaks. Tunnuse INTSCIE (huvi teaduse vastu) regressioonikordaja on 10.600. Kui see muutuja suureneb ühe punkti võrra, võib eeldada testiskoori 10.6-punktist kasvu (jällegi eeldusel, et ülejäänud sõltumatud muutujad on konstantsed). Tunnuse INSTSCIE (motivatsioon teaduse õppimiseks) regressioonikordaja on mingil põhjusel negatiivne (-9.236). Kui see muutuja suureneb ühe punkti võrra, langeb testiskoor umbes 9.2 punkti võrra.</p>
<p>Kõigi prediktorite kohta on ära toodud standardvead (tulbas <strong>Std. Error</strong>), t-statistikud (regressioonikordaja jagatud standardveaga) ning p-väärtused, mille abil saame otsustada, kas tegemist on statistiliselt usaldusväärse prediktoriga. P-väärtused on jällegi tootud teaduslikku tähistust kasutades, aga nad kõik on väga väikesed ja seega on kõik prediktorid statistiliselt olulised. Kui selline tähistus tundub silmale natuke keeruline, siis olulisusele viitavad ka ridade lõpus olevad tärnid. Tärnide arvule vastavad olulisusenivood on toodud Coefficients tabeli all.</p>
<p>Teades mudeli parameetrite väärtusi saaksime vajadusel kirja panna muutujate-vahelisi seoseid väljendava regressioonivõrrandi (ümmardades parameetrid ühe komakohani):</p>
<p><span class="math display">\[loodusteaduste testi skoor = 528.9 + 30.7 * teaduse oluliseks pidamine + 10.6 * huvi teaduse vastu - 9.2 * motivatsioon õppida teadust\]</span></p>
<div id="prediktorite-vordlemine" class="section level2">
<h2>Prediktorite võrdlemine</h2>
<div id="t-statsitk" class="section level3">
<h3>T-statsitk</h3>
<p>Mitme sõltumatu muutujaga regressioonimudeli puhul saab t-statistikuid kasutada ka prediktorite suhtelise olulisuse võrdlemiseks. Antud juhul on teaduse oluliseks pidamine suuremat mõju omav prediktor (t = 23.598) kui huvi (6.498) või motivatsioon (-6.062). Kahe viimase panus on enam-vähem võrdne.</p>
</div>
<div id="standradiseeritud-regressioonikordaja-ehk-beeta-kordaja" class="section level3">
<h3>Standradiseeritud regressioonikordaja ehk beeta-kordaja</h3>
<p>Teist tüüpi näitaja, mida prediktorite olulisuse võrdlemiseks sageli kasutatakse on standardiseeritud regressioonikordajad ehk niinimetatud beeta-kordajad. Need ütlevad, mitme standardhälbe võrra muutub sõltuv muutuja, kui prediktor muutub ühe standardhälbe võrra (ja ülejäänud prediktorid jäävad samaks).</p>
<p>Standardhälbe ühikute kasutamine muudab eri muutujate kordajad otseselt võrreldavaks, kuna neid ei mõjuta see, kui prediktoreid on mõõdetud erinevates ühikutes. R-is saame need kätte lisamooduli <em>QuantPsyc</em> funktsiooni <em>lm.beta</em> abil, millele anname mudeli nime. Kasutamiseks tuleks kõigepealt see lisamoodul installida…</p>
<pre class="r"><code>install.packages(&quot;QuantPsyc&quot;)</code></pre>
<p>…ja laadida.</p>
<pre class="r"><code>library(QuantPsyc)
lm.beta(pisa.mudel2)</code></pre>
<pre><code>##     GENSCIE     INTSCIE    INSTSCIE 
##  0.33865407  0.09891640 -0.09066222</code></pre>
<p>Näeme, et GENSCIE <strong>beeta-kordaja</strong> on umbes 0.34 ja teiste muutujade omad 0.10-kanti. (Mõju suuruse võrdlemisel on oluline kordaja absoluutväärtus, miinusmärk INSTSCIE kordaja ees näitab mõju suunda.) Seega võime öelda, et GENSCIE mõju loodusteaduste alatesti skoorile on laias laastus 3 korda suurem kui kahel ülejäänud muutujal.</p>
</div>
<div id="usalduspiirid" class="section level3">
<h3>Usalduspiirid</h3>
<p>Veel üks näitaja, mida regressioonikordajate kvaliteedi uurimiseks suhteliselt sageli kasutatakse on 95%-usalduspiirid. R-is saame need funktsiooni <em>confint</em> abil, millele anname mudeli nime</p>
<pre class="r"><code>confint(pisa.mudel2)</code></pre>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) 526.676439 531.061743
## GENSCIE      28.118769  33.214203
## INTSCIE       7.401992  13.797590
## INSTSCIE    -12.222315  -6.249079</code></pre>
<p>95%-usalduspiirid tähendavad, et kui meil oleks ühe valimi asemel 100 valimit, siis 95-l juhul langevad mudeli parameetrite väärtused piiride vahemikku. Mida kitsam parameetri usaldusvahemik, seda parem. Samuti tahame, et prediktori usalduspiirid jääksid ühele poole nullpunkti. Kui nullpunkt jääb usaldusvahemiku sisse tähendab see, et mõnedes valimites oleks prediktori mõju positiivse ja teistes negatiivse suunaga. Kõigi prediktorite vahemikud üsna kitsad ja samasuguse suurusega. Võime eeldada, et mõnes teises samalaadses valimis on oodata üsna samasuguseid regressioonikordajajaid. Ka ei ületa ühegi muutuja usalduspiirid nullpunkti ja seega võib neid pidada usaldusväärseteks.</p>
</div>
</div>
<div id="ulesanded---mitmene-regressioon" class="section level2">
<h2>Ülesanded - mitmene regressioon</h2>
<ol style="list-style-type: decimal">
<li>Koostage uus mudel, milles sõltuvaks tunnuseks on matemaatika testi skoor (PVMATH) ja prediktoriteks samad tunnused, millega ülal ennustasime loodusteaduste testi skoori: teaduse oluliseks pidamine (GENSCIE), huvi teaduse vastu (INTSCIE) ja motivatsioon loodusteadusi õppida (INSTSCIE). Missugused prediktorid on statistiliselt olulised? Arvutage ka standardiseeritud regressioonikordajad ja mudeli parameetrite usalduspiirid.</li>
</ol>
</div>
</div>
<div id="hierarhiliste-mudelite-vordlemine" class="section level1">
<h1>Hierarhiliste mudelite võrdlemine</h1>
<p>Mudelid <em>pisa.mudel1</em> ja <em>pisa.mudel2</em> on hierarhilised.</p>
<pre class="r"><code>pisa.mudel1 &lt;- lm(PVSCIE ~ GENSCIE, data = pisa)
pisa.mudel2 &lt;- lm(PVSCIE ~ GENSCIE + INTSCIE + INSTSCIE, data=pisa)</code></pre>
<p>See tähendab, et <em>pisa.mudel2</em> on saadud <em>pisa.mudel1</em>-le prediktoreid lisades. Hierarhiliste mudelite puhul saame arvutada statistilise usaldusväärsuse sellele, kas teine mudel on esimesest parem ehk kas prediktorite lisamine tegi mudelit paremaks. Mitte-hierarhiliste mudelite puhul seda teha ei saa. Nt me ei saa niimoodi võrrelda mudelit pisa.mudel1 (PVSCIE ~ GENSCIE) mudeliga, milles prediktoriteks oleksid INTSCIE ja INSTSCIE ilma GENSCIE-ta (PVSCIE ~ INTSCIE + INSTSCIE). Mudelite võrdlemiseks kasutame R-i funktsiooni <em>anova</em>.</p>
<pre class="r"><code>anova(pisa.mudel1, pisa.mudel2)</code></pre>
<pre><code>## Warning in anova.lmlist(object, ...): models with response &#39;&quot;PVSCIE&quot;&#39;
## removed because response differs from model 1</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: pisa$PVSCIE
##                Df   Sum Sq Mean Sq F value    Pr(&gt;F)    
## pisa$GENSCIE    1  3630834 3630834  650.23 &lt; 2.2e-16 ***
## Residuals    4766 26613057    5584                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Eelkõige peaksime vaatama väljundis oleva tabeli viimase rea kahte parempoolset tulpa, milles on ära toodud mudelite erinevuse <strong>F-suhe</strong> ja selle <strong>p-väärtus</strong>. P-väärtus on praegusel juhul 2.791e-13 ehk 2.79 * <span class="math inline">\(10^{-13}\)</span> ehk p &lt; 0.001. Seega on tõenäosus, et nii suur F-suhte väärtus on saadud ainult tänu juhusele alla 0.1%-i ja võime tõdeda, et teine mudel on esimesest oluliselt parem. Kuigi ilmselt suuresti tänu meie väga suurele valimile, mille puhul ka üsnagi väikesed erinevused on statistiliselt olulised.</p>
</div>
<div id="erindid" class="section level1">
<h1>Erindid</h1>
<p>Seda, kas koostatud mudel sobib andmetega hästi, võib hinnata ka äärmuslike erindite abil. Erindid on need vaatlused (see tähendab andmeread, meie puhul vastajad), mis erinevad märkimisväärselt peamisest andmetes esinevast trendist. Sellised juhtumid leiame üles mudeli jääkide abil. (Jäägid mäletatavasti kujutasid endast tegelike andmete ja mudeli põhjal arvutatud väärtuste erinevust.) Tavapärased mudeli jäägid on samades ühikutes, milles on mõõdetud sõltuvat muutujad. Nende puhul on natuke raske otsustada, kui suurt jääki pidada suureks. Lihtsam on vaadata standardiseeritud jääke, mis on standardhälbe ühikutes. Kui selliste standardiseeritud jääkide osakaal, mille absoluutväärtus on üle kahe, on rohkem kui 5%, võib öelda, et mudel ei esinda meie andmeid väga hästi. Arvutame kõigepealt standardiseeritud jäägid funktsiooniga <em>rstandard</em> ja salvestame need muutujasse nimega <em>mud2.standardized.residuals</em>. (Kui selline pikk ja lohisev nimi ei meeldi, võib valida ka mõne lühema. Pikema nime eeliseks on aga, et selle abil on kergem aru saada, mis nime taga peitub.)</p>
<pre class="r"><code>mud2.standardized.residuals &lt;- rstandard(pisa.mudel2)</code></pre>
<p>Nüüd peame teada saama, kui palju on jääke absoluutväärtusega üle kahe. Absoluutväärtused saame funktsiooni <em>abs</em> abil, paneme nende kõrvale tingimuse (&gt; 2) ja selle kõige ümber funtsiooni sum, mis loeb kokku, palju on sellele tingimusele vastavaid jääke.</p>
<pre class="r"><code>sum(abs(mud2.standardized.residuals) &gt; 2)</code></pre>
<pre><code>## [1] 208</code></pre>
<p>Selliseid jääke on 208. Otsustamaks, kas see on rohkem kui 5%, peame teadma oma andmestiku suurust ehk tabeli pisa ridade arvu ja korrutama selle 0.05-ga. Ridade arvu saab kas RStudio Environment-paneelist (üleval paremal) või funktsiooni <em>nrow</em> abil.</p>
<pre class="r"><code>nrow(pisa) * 0.05</code></pre>
<pre><code>## [1] 238.4</code></pre>
<p>5 protsenti on antud juhul 238 ja kuna suuri jääke oli 208, võime järeldada, et neid on alla kriitilise piiri. Standardiseeritud jäägid absoluutväärtusega üle 3-e aitavad, meil üles leida vaatlused, millele koostatud mudel kohe üldse ei sobi. Selliste vaatluste arvu saame taas kasutades funktsioone sum ja abs.</p>
<pre class="r"><code>sum(abs(mud2.standardized.residuals) &gt; 3)</code></pre>
<pre><code>## [1] 10</code></pre>
<p>Nii suuri jääke on 10. Selliseid äärmuslikke erindeid tasuks reeglina lähemalt uurida. Need saame tabelist kätte kasutades tabeli nime, nurksulge ja tingimust, millele meid huvitavad read vastama peavad.</p>
<pre class="r"><code>pisa[abs(mud2.standardized.residuals) &gt; 3, ]</code></pre>
<pre><code>##         X   PVMATH   PVREAD   PVSCIE GENSCIE INSTSCIE INTSCIE JOYSCIE
## 53     53 676.8111 590.1395 722.9844 -1.6486  -0.4167 -0.5440 -0.8455
## 1797 1797 301.6747 216.5256 279.2202 -0.3580   0.7257  0.0663 -0.1028
## 2733 2733 709.9938 601.6094 767.2769  0.0792   1.8212  1.9779  2.0562
## 3135 3135 693.1687 665.8147 778.0936  0.4867   0.0195  0.6732  0.1728
## 3308 3308 284.6939 286.6283 314.4677  0.4867   0.7257  0.2143 -0.3437
## 3393 3393 253.6922 275.1020 308.3133  0.4867   0.9603  0.6732  0.8776
## 3447 3447 251.5890 218.4506 250.7797  0.4867   1.1694  1.2778  0.1728
## 4052 4052 315.3840 252.2988 299.3616  0.8962   0.9603  1.4176  0.1728
## 4645 4645 375.4401 331.1444 394.7537  2.1867   0.3719  3.2888  0.8776
## 4702 4702 387.3578 354.3248 370.3228  2.1867   1.1694  1.0131 -0.8455
##      PERSCIE SCIEEFF SCIEFUT  SCSCIE GR GENDER
## 53   -0.8110 -0.3985 -0.0492 -0.8207  9      M
## 1797  0.7259 -0.3985 -0.0492 -0.5445  7      M
## 2733  2.5264  3.2230  1.8262  2.2442  9      M
## 3135  1.0558  0.5179  0.8285  2.2442  9      F
## 3308  0.7259 -0.5654 -0.0492 -0.8207  8      M
## 3393  1.3959 -0.0337  0.8285  1.2090  8      F
## 3447  0.3867  0.1288  1.5467  1.3981  8      M
## 4052  0.7259 -0.7309  1.5467  1.3981  9      M
## 4645  2.5264  1.2058  1.3025  1.3981  9      M
## 4702  2.5264 -0.2283 -0.0492 -0.8207  9      M</code></pre>
<p>Antud juhul on tegemist meile üsna võõra andmestikuga ja me ei oska täpselt öelda, mis erindite põhjuseks võib olla. Kui me aga juhtume töötama andmetega, mida lähemalt tunneme, oskame paremini hinnata, kas nende puhul on midagi kahtlast, mis on kaasa toonud selle, et need juhtumid mudeliga hästi ei sobi. Samas ei tohiks suurte jääkidega vaatlusi väga kergekäeliselt välja visata, vaid ainult siis, kui tegemist on ilmselgelt kahtlaste asjaoludega (nt näpuviga andmete sisestamisel). Praegu on meil tegemist suure valimiga ning erindid väljenduvad peamiselt selles, et mudel nende kirjeldamiseks hästi ei sobi. Väiksemate valimite puhul võib ette tulla vastupidine olukord: üks teistest selgelt eristuv väärtus hakkab kallutama mudelit enda suunas. Kuna sellised vaatlused on väga mõjukad ja kallutanud mudeli endale vastavamaks, ei pruugi nende jääk olla üldsegi suur. Samas ei pruugi mudel andmetega hästi sobida, sest ülejäänud omavahel sarnasemate vaatluste jäägid on selle tõttu omakorda suurenenud. Selliste mõjukate juhtumite avastamiseks saab kasutada näitajaid, mida nimetatakse <strong>Cooki kaugusteks</strong> ning mille puhul annavad <strong>ühest suuremad väärtused</strong> põhjust kõrgendatud tähelepanuks. Need näitajad saame arvutada funktsiooni <em>cooks.distance</em> abil, millele anname ette mudeli. Kasutame seda praegu koos funktsiooniga <em>max</em>, et leida, kui suur on meie mudeli puhul kõige suurem Cooki kaugus.</p>
<pre class="r"><code>max(cooks.distance(pisa.mudel2))</code></pre>
<pre><code>## [1] 0.01945075</code></pre>
<p>See on umbes 0.02, mis jääb ühest üsna kaugele, järelikult liigselt mõjukate juhtumitega meil praegu probleeme pole (nagu oodata oligi). Kui meil esineks selliseid juhtumeid saaksime need kätte nii:</p>
<pre class="r"><code>pisa[cooks.distance(pisa.mudel2) &gt; 1,]</code></pre>
<pre><code>##  [1] X        PVMATH   PVREAD   PVSCIE   GENSCIE  INSTSCIE INTSCIE 
##  [8] JOYSCIE  PERSCIE  SCIEEFF  SCIEFUT  SCSCIE   GR       GENDER  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<p>Kuna meil selliseid juhtumeid polnud, siis pragusel juhul saime tagasi tühja tabeli, milles 0 rida. Juhul kui meil mõjukaid juhtumeid esineb ja tahame mudelit korrata ilma nendeta, saab seda teha andes funktsioonile lm argumendi subset abil tingimuse, mille alusel vaatlusi mudelist välja jätta. Paigutame kõigepealt Cooki kaugused muutujasse nimega <em>cooki.kaugused</em>. Seejärel teeme mudeli funktsioonga lm kasutades lisaargumenti subset, mille abil kaasame ainult vaatlused, mille puhul on Cooki kauguse väärtus alla ühe.</p>
<pre class="r"><code>cooki.kaugused &lt;- cooks.distance(pisa.mudel2)</code></pre>
<pre class="r"><code>pisa.mudel3 &lt;- lm(PVSCIE ~ GENSCIE + INTSCIE + INSTSCIE,
data=pisa,
subset=cooki.kaugused&lt;1)</code></pre>
<p>See koodijupp oli ainult näitlikustamiseks, kuna meil praegu suuri kaugusi ei esinenud, tuleb uus mudel täpselt samasugune kui <em>pisa.mudel2</em>.</p>
</div>
<div id="mudeli-uldistamise-eeldused" class="section level1">
<h1>Mudeli üldistamise eeldused</h1>
<p>Enamasti tahame oma analüüsi tulemusi üldistada <span class="math inline">\(-\)</span> teha järeldusi mitte ainult oma valimi, vaid mingite suuremate inimrühmade või muu taolise kohta. Selleks peab olema täidetud rida eeldusi. Ka eelduste täitmisel võib juhtuda, et kui mudelit korrata suurema valimiga, saame teistsuguse tulemuse, aga vähemalt suurendab see sarnase tulemuse tõenäosust. Kui eeldusi rikutakse, pole mudeli üldistamine korrektne, küll saame jätkuvalt öelda, et tulemused kehtivad valimi kohta, mille põhjal me mudeli koostasime.</p>
<div id="multikollineaarsus" class="section level2">
<h2>Multikollineaarsus</h2>
<p>Üheks probleemiks, mis esineda võib, on multikollineaarsus ehk olukord, kui mudeli prediktorid on omavahel liiga tugevalt korreleeritud. Multikollineaarsuse esinemine suurendab regressioonikordajate standardvigasid, mis tähendab, et need on vähem usaldusväärsed ja seetõttu on tõenäosus saada samasuguseid kordajaid teistes valimites väiksem. Probleemse multikollineaarsuse avastamiseks võime vaadata prediktorite-vahelisi korrelatsioone. Need saame andes funktsioonile <em>cor</em> meid huvitavad tabeli tulbad.</p>
<pre class="r"><code>cor(pisa[,c(&quot;GENSCIE&quot;, &quot;INTSCIE&quot;, &quot;INSTSCIE&quot;)])</code></pre>
<pre><code>##            GENSCIE   INTSCIE  INSTSCIE
## GENSCIE  1.0000000 0.3088645 0.2506105
## INTSCIE  0.3088645 1.0000000 0.4085926
## INSTSCIE 0.2506105 0.4085926 1.0000000</code></pre>
<p>Saame tagasi korrelatsioonimaatriksi. Problemaatilised on muutujatevahelised korrelatsioonid absoluutväärtusega &gt; 0.8. Kui selliseid esineb, tasuks üks tugevalt korreleeritud muutujatest mudelist välja jätta.</p>
<p>Praegu on tugevaim korrelatsioon umbes 0.4 (INTSCIE ja INSTSCIE vahel). Veel üks näitaja, mis aitab multikollineaarsust avastada on muutujate variatsiooniindeksid, mille abil saame funktsiooni <em>vif</em> abil, andes sellele ette mudeli nime. See tuleb lisamoodulist <em>car</em>, mille peame eelnevalt installima.</p>
<pre class="r"><code>install.packages(&quot;car&quot;)</code></pre>
<p>Nüüd saame mooduli laadida ja kasutada funktsiooni <em>vif</em>.</p>
<pre class="r"><code>library(car)
vif(pisa.mudel2)</code></pre>
<pre><code>##  GENSCIE  INTSCIE INSTSCIE 
## 1.128639 1.269734 1.225578</code></pre>
<p>Indeksi väärtused üle 10-e annavad märku probleemsest multikollineaarsusest. Praegusel juhul selliseid väärtusi ei esine.</p>
</div>
<div id="heteroskedaktilisus" class="section level2">
<h2>Heteroskedaktilisus</h2>
<p>Teine keerulise nimega probleem, mis võib takistada mudeli järelduste üldistamist on heteroskedaktilisus ehk olukord kui mudeli jääkide hajuvus on prediktorite eri tasemetel liiga erinev. Nähtuse esinemist saame uurida hajuvusdiagrammi abil, mille ühel teljel on mudeli jäägid (saame funtksioon resid abil) ja teisel teljel mudeli poolt ennustatud väärtused (need saame funktsiooni fitted.values abil).</p>
<pre class="r"><code>library(ggplot2)
plot(fitted.values(pisa.mudel2), resid(pisa.mudel2))</code></pre>
<p><img src="praktikum4_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Joonisel olev punktikogum peaks olema ühtlane, see ei tohiks olla lehtrikujuline ehk ühes servast märkimisv äärselt kitsam kui teises servas. Antud juhul see enam-vähem nii ongi. Silma hakkavad üksikud eristuvad andmepunktid (see on suure valimi puhul oodatav), aga mitte midagi süstemaatilist. (Lisaks sellele: kui antud joonisel ilmneb U-kujuline muster, viitab see, et muutujate vaheline seos pole päris lineaarne.)</p>
</div>
<div id="jaakide-normaaljaotus" class="section level2">
<h2>Jääkide normaaljaotus</h2>
<p>Kolmas üldistamise eeldus, mida alguses põgusalt mainitud sai, on, et mudeli jäägid peavad olema normaaljaotusega.</p>
<p>Sellest annab aimu mudeli jääkide histogramm.</p>
<pre class="r"><code>hist(mud2.standardized.residuals)</code></pre>
<p><img src="praktikum4_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Teist tüüpi joonis, mille abil jääkide normaaljaotusele vastavust uurida on niinimetatud tõenäosuspaber ehk kvantiil-kvantiil diagramm (ingl. k. <em>Q-Q plot</em>). Selle saame kasutades funktsioone <em>qqnorm</em> ja <em>qqline</em> ja andes neile ette mudeli jäägid.</p>
<pre class="r"><code>qqnorm(mud2.standardized.residuals)
qqline(mud2.standardized.residuals, col=&quot;red&quot;, lwd=2)</code></pre>
<p><img src="praktikum4_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>Sirge joon esindab normaaljaotust ja punktid jääke. Täiusliku normaaljaotuse korral oleksid kõik punktid joone peal. Kõrvalekalded joonest on tavalised otstes, kuid keskel ei tohiks tohiks neid esineda. Praegu me midagi sellist näemegi; otstes on väikesed kõrvalekalded, aga mitte midagi hullu silma ei hakka.</p>
</div>
<div id="jaakide-soltumatus" class="section level2">
<h2>Jääkide sõltumatus</h2>
<p>Veel üks jääke puudutav mudeli üldistamise eeldus on jääkide sõltumatus, mis tähendab, et ei tohi esineda liiga palju üksteisega sarnanevaid jääke. Seda eeldust saab kontrollida <strong>Durbin-Watsoni testi</strong> abil, mille saame lisamoodulis <em>car</em> paikneva funtsiooni <em>dwt</em> abil, millele anname ette mudeli-objekti. (Kuna eelnevalt selle mooduli installisime ja laadisime pole seda praegu enam vaja teha.)</p>
<pre class="r"><code>dwt(pisa.mudel2)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1      0.04833149      1.902115       0
##  Alternative hypothesis: rho != 0</code></pre>
<p>Vaatame väljundis numbrit, mille kohale on kirjutatud <strong>D-W Statistic</strong>. Selle soovitav väärtus on vahemikus 1 kuni 3, mida lähemal 2-le, seda parem. Antud juhul statistiku väärtuseks 1.9, mille põhjal võime järeldada, et meil pole jääkide sõltumatusega probleeme.</p>
</div>
</div>
<div id="ulesanded" class="section level1">
<h1>Ülesanded</h1>
<p>Analüüsige lähemalt eelnevalt tehtud mudelit, kus sõltuvaks tunnuseks oli matemaatika testi skoor (PVMATH) ja prediktoriteks teaduse oluliseks pidamine (GENSCIE), huvi teaduse vastu (INTSCIE) ja motivatsioon loodusteadusi õppida (INSTSCIE).</p>
<ol style="list-style-type: lower-alpha">
<li>Arvutage mudeli standardiseeritud jäägid. Kui suur on jääkide osakaal, mille absoluutväärtus on suurem kui 2? Kas neid on liiga palju?<br />
</li>
<li>Arvutage mudeli kohta Cooki kaugused. Kas esineb liiga suure mõjukuseastmega vaatlusi?<br />
</li>
<li>Kas mudelil on probleeme multikollineaarsuse, heteroskedaktilisuse, jääkide jaotuse või jääkide sõltumatusega?</li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
